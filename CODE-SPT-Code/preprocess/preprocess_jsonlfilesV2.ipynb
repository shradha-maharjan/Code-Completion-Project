{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines of code processed: 181061\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "STRING_MATCHING_PATTERN = re.compile(r'([bruf]*)(\\\"\\\"\\\"|\\'\\'\\'|\\\"|\\')(?:(?!\\2)(?:\\\\.|[^\\\\]))*\\2')\n",
    "\n",
    "lang_dir = '/home/user1-selab3/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java'\n",
    "\n",
    "def replace_string_literal(source):\n",
    "    \"\"\"\n",
    "    Replace the string literal in source code with ``<STR>``.\n",
    "\n",
    "    Args:\n",
    "        source (str): Source code in string\n",
    "\n",
    "    Returns:\n",
    "        str: Code after replaced\n",
    "\n",
    "    \"\"\"\n",
    "    return re.sub(pattern=STRING_MATCHING_PATTERN, repl='___STR', string=source)\n",
    "\n",
    "def parse_java_json_file(file_path):\n",
    "    # sources, codes, names = [], [], []\n",
    "    sources = []\n",
    "    codes =[]\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line.strip())\n",
    "            source = data['code'].strip()\n",
    "            source = replace_string_literal(source)\n",
    "            code = replace_string_literal(' '.join(data.get('code_tokens', [])))\n",
    "            sources.append(source)\n",
    "            codes.append(code)\n",
    "    return sources,codes\n",
    "\n",
    "\n",
    "def iter_all_files(base):\n",
    "    for root, dirs, files in os.walk(base):\n",
    "        for f in files:\n",
    "            yield os.path.join(root, f)\n",
    "\n",
    "def iter_pre_train_dataset_files(lang_dir, lang=\"Java\"):\n",
    "    return [file for file in iter_all_files(base=lang_dir) if file.endswith('.jsonl')]\n",
    "\n",
    "total_lines = 0\n",
    "\n",
    "file_paths = iter_pre_train_dataset_files(lang_dir)\n",
    "for file_path in file_paths:\n",
    "    sources, codes = parse_java_json_file(file_path)\n",
    "    total_lines += len(codes)\n",
    "\n",
    "print(f\"Total lines of code processed: {total_lines}\")\n",
    "# file_paths = iter_pre_train_dataset_files(lang_dir)\n",
    "# for file_path in file_paths:\n",
    "#     sources, codes = parse_java_json_file(file_path)\n",
    "#     for source, code in zip(sources, codes):\n",
    "#         print(f\"Source Code:\\n{source}\\n\")\n",
    "#         print(f\"Code Tokens:\\n{code}\\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique lines written to output: 181060\n"
     ]
    }
   ],
   "source": [
    "lang_dir = '/home/user1-selab3/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java'\n",
    "\n",
    "output_path = '/home/user1-selab3/Documents/research-shradha/CODE-SPT-Code/preprocess/pretrain_code_tokens.txt'\n",
    "\n",
    "# To avoid duplicates, we use a set to track unique code entries\n",
    "unique_codes = set()\n",
    "line_count = 0\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "    file_paths = iter_pre_train_dataset_files(lang_dir)\n",
    "    for file_path in file_paths:\n",
    "        _, codes = parse_java_json_file(file_path)\n",
    "        for code in codes:\n",
    "            if code not in unique_codes:  # Check if the code line is unique\n",
    "                output_file.write(code + \"\\n\")\n",
    "                unique_codes.add(code)  # Add to set to avoid duplicates\n",
    "                line_count += 1\n",
    "\n",
    "print(f\"Total unique lines written to output: {line_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_python3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
