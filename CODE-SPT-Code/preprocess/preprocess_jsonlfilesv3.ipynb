{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines across all .jsonl files: 181061\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_lines_in_jsonl_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        line_count = sum(1 for line in file)\n",
    "        return line_count\n",
    "\n",
    "def count_lines_in_jsonl_files(directory):\n",
    "    total_line_count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jsonl\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            total_line_count += count_lines_in_jsonl_file(filepath)\n",
    "\n",
    "    print(f\"Total lines across all .jsonl files: {total_line_count}\")\n",
    "\n",
    "directory_path = '/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java' \n",
    "count_lines_in_jsonl_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines of code processed: 0 (0, 0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "STRING_MATCHING_PATTERN = re.compile(r'([bruf]*)(\\\"\\\"\\\"|\\'\\'\\'|\\\"|\\')(?:(?!\\2)(?:\\\\.|[^\\\\]))*\\2')\n",
    "\n",
    "flag_normalize = flag_join = False\n",
    "\n",
    "def replace_string_literal(source):\n",
    "    return re.sub(pattern=STRING_MATCHING_PATTERN, repl='___STR', string=source)\n",
    "\n",
    "def parse_java_json_file(file_path):\n",
    "    sources = []\n",
    "    codes = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        counter_line = 0\n",
    "        for line in file:\n",
    "            counter_line += 1\n",
    "            data = json.loads(line.strip())\n",
    "            if flag_normalize == True:\n",
    "                code = replace_string_literal(' '.join(data.get('code_tokens', [])))\n",
    "            elif flag_join == True:\n",
    "                code = (' '.join(data.get('code_tokens', [])))\n",
    "            else:\n",
    "                code = data.get('code_tokens')\n",
    "            codes.append(code)\n",
    "    return sources,codes,counter_line\n",
    "\n",
    "def iter_all_files(base):\n",
    "    for root, dirs, files in os.walk(base):\n",
    "        for f in files:\n",
    "            yield os.path.join(root, f)\n",
    "\n",
    "def iter_pre_train_dataset_files(lang_dir, lang=\"Java\"):\n",
    "    return [file for file in iter_all_files(base=lang_dir) if file.endswith('.jsonl')]\n",
    "\n",
    "lang_dir = './dataset/pre_train/java'\n",
    "# extracting 'code_tokens' from 3 jsonl files.\n",
    "output_file_path = '/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/preprocess/pre_train_code_tokens_combine_all3jsonl.txt'\n",
    "total_lines = total_linesV2 = total_linesV3 = 0\n",
    "jsonl_files_pretrain_data = iter_pre_train_dataset_files(lang_dir)\n",
    "codes_all = []\n",
    "\n",
    "for file_pretrain_data in jsonl_files_pretrain_data:\n",
    "    sources, codes, counter_line = parse_java_json_file(file_pretrain_data)\n",
    "    codes_all.extend(codes)\n",
    "    total_lines += len(codes)\n",
    "    total_linesV2 += counter_line\n",
    "    print(f'{file_pretrain_data}: {counter_line}')\n",
    "\n",
    "print(f\"Total lines of code processed: {total_lines} ({total_linesV2}, {len(codes_all)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pre_train_code_tokens_combine_all3jsonl.csv as CSV file with lines, 0.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "output_file_path_csv = 'pre_train_code_tokens_combine_all3jsonl.csv'\n",
    "\n",
    "with open(output_file_path_csv, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    #csv_writer.writerow(['Index', 'Code'])\n",
    "    for idx, code in enumerate(codes_all):\n",
    "        csv_writer.writerow([idx, code])\n",
    "\n",
    "print(f\"Saved {output_file_path_csv} as CSV file with lines, {count_lines_in_jsonl_file(output_file_path_csv)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/train.jsonl: 164923\n",
      "Total lines of code processed: 164923 (164923, 164923)\n"
     ]
    }
   ],
   "source": [
    "file_pretrain_data = '/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/train.jsonl'\n",
    "codes_all = []\n",
    "\n",
    "sources, codes, counter_line = parse_java_json_file(file_pretrain_data)\n",
    "codes_all.extend(codes)\n",
    "total_lines += len(codes)\n",
    "total_linesV2 += counter_line\n",
    "print(f'{file_pretrain_data}: {counter_line}')\n",
    "\n",
    "print(f\"Total lines of code processed: {total_lines} ({total_linesV2}, {len(codes_all)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# file_path = '/Users/myoungkyu/Documents/0-research-spt-code-data/research-spt-code-data/py/output_divide_train_group16/group44/train_part_2.jsonl'\n",
    "# file_path = '/Users/myoungkyu/Documents/0-research-spt-code-data/research-spt-code-data/py/output_divide_train_group16/train_part_44.jsonl'\n",
    "file_path = '/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/train.jsonl'\n",
    "output_file_path_csv = '/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/pre_train_code_tokens_tmp.csv'\n",
    "\n",
    "def count_lines_in_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        line_count = sum(1 for line in file)\n",
    "        return line_count\n",
    "\n",
    "def parse_java_json_file(file_path):\n",
    "    index_line = counter_problem = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            index_line += 1\n",
    "            data = json.loads(line.strip())\n",
    "            code = (' '.join(data.get('code_tokens', [])))\n",
    "            codes = []\n",
    "            codes.append(code)\n",
    "\n",
    "            with open(output_file_path_csv, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "                csv_writer = csv.writer(csv_file)\n",
    "                for idx, code in enumerate(codes):\n",
    "                    csv_writer.writerow([idx, code])\n",
    "\n",
    "            if count_lines_in_file(output_file_path_csv) != len(codes):\n",
    "                counter_problem += 1\n",
    "                print(f\"{index_line}: lines written file: {count_lines_in_file(output_file_path_csv)}, data len: {len(codes)}.\")\n",
    "        \n",
    "        print(f'# of problems: {counter_problem}')\n",
    "\n",
    "parse_java_json_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "file_path = '/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/train.jsonl'\n",
    "output_file_path_csv = '/home/user1-system11/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/pre_train_code_tokens_tmp.csv'\n",
    "\n",
    "skip_lines = {\n",
    "    127273, 127274, 127275, 127279, 127280, 127281, 127282, 127283, 127284,\n",
    "    141780, 141824, 141835, 141847, 141850\n",
    "}\n",
    "\n",
    "def count_lines_in_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        line_count = sum(1 for line in file)\n",
    "        return line_count\n",
    "\n",
    "def parse_java_json_file(file_path, skip_lines):\n",
    "    codes = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for i, line in enumerate(file, start=1):\n",
    "            if i not in skip_lines:\n",
    "                data = json.loads(line.strip())\n",
    "                code = (' '.join(data.get('code_tokens', [])))\n",
    "                codes.append(code)\n",
    "    return codes\n",
    "\n",
    "def check_data_savedfile(src_file_path, skip_lines):\n",
    "    codes = parse_java_json_file(src_file_path, skip_lines)\n",
    "\n",
    "    with open(output_file_path_csv, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        for idx, code in enumerate(codes):\n",
    "            csv_writer.writerow([idx, code])\n",
    "\n",
    "    print(f\"Saved {output_file_path_csv}, file's lines: {count_lines_in_file(output_file_path_csv)}, data len: {len(codes)}.\")\n",
    "\n",
    "print(\"Case 1: with problems\")\n",
    "check_data_savedfile(file_path, [])\n",
    "print(\"Case 2: removed problems\")\n",
    "check_data_savedfile(file_path, skip_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4code-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
