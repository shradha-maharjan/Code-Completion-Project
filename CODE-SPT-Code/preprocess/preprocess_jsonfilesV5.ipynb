{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "STRING_MATCHING_PATTERN = re.compile(r'([bruf]*)(\\\"\\\"\\\"|\\'\\'\\'|\\\"|\\')(?:(?!\\2)(?:\\\\.|[^\\\\]))*\\2')\n",
    "                                    \n",
    "def replace_string_literal(source):\n",
    "    return re.sub(pattern=STRING_MATCHING_PATTERN, repl='___STR', string=source)\n",
    "\n",
    "file_path = '/home/user1-selab3/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/valid.jsonl'\n",
    "file_path = '/home/user1-selab3/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/test.jsonl'\n",
    "file_path = '/home/user1-selab3/Documents/research-shradha/CODE-SPT-Code/dataset/pre_train/java/train.jsonl'\n",
    "output_file_path_txt = 'codetokens-valid.txt'\n",
    "output_file_path_txt = 'codetokens-test.txt'\n",
    "output_file_path_txt = 'codetokens-train.txt'\n",
    "\n",
    "skip_lines = {\n",
    "    127273, 127274, 127275, 127279, 127280, 127281, 127282, 127283, 127284,\n",
    "    141780, 141824, 141835, 141847, 141850\n",
    "}\n",
    "\n",
    "isGeneralized = False\n",
    "if isGeneralized == False:\n",
    "    output_file_path_txt = 'codetokens-valid-nongen.txt'\n",
    "    output_file_path_txt = 'codetokens-test-nongen.txt'\n",
    "    output_file_path_txt = 'codetokens-train-nongen.txt'\n",
    "\n",
    "def count_lines_in_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        line_count = sum(1 for line in file)\n",
    "        return line_count\n",
    "\n",
    "def read_json_get_value(file_path, skip_lines):\n",
    "    codes = []\n",
    "    counter_problem_quote = counter_after_skip = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for i, line in enumerate(file, start=1):\n",
    "            if i not in skip_lines:\n",
    "                counter_after_skip += 1\n",
    "                data = json.loads(line.strip())\n",
    "                code = (' '.join(data.get('code_tokens', [])))\n",
    "\n",
    "                # check 1: count double or single quotes\n",
    "                double_quote_count = single_quote_count = 0\n",
    "                double_quote_count += line.count('\"')\n",
    "                single_quote_count += line.count(\"'\")\n",
    "                if double_quote_count % 2 != 0 or single_quote_count % 2 != 0:\n",
    "                    # print(\"Inconsistent quotes detected in the file.\")\n",
    "                    counter_problem_quote += 1\n",
    "                    continue\n",
    "                if isGeneralized == True:\n",
    "                    code = replace_string_literal(code)\n",
    "                codes.append(code)\n",
    "    print(f'# of problem_quote: {counter_problem_quote}, counter_after_skip: {counter_after_skip}')\n",
    "    return codes\n",
    "\n",
    "def check_data_savedfile(src_file_path, skip_lines):\n",
    "    codes = read_json_get_value(src_file_path, skip_lines)\n",
    "\n",
    "    with open(output_file_path_txt, 'w', encoding='utf-8') as txt_file:\n",
    "        for idx, code in enumerate(codes):\n",
    "            txt_file.write(f\"{code}\\n\")\n",
    "\n",
    "    print(f\"Saved {output_file_path_txt}, file's lines: {count_lines_in_file(output_file_path_txt)}, data len: {len(codes)}.\")\n",
    "\n",
    "print(\"Case 1: with problems\")\n",
    "check_data_savedfile(file_path, [])\n",
    "print(\"Case 2: removed problems\")\n",
    "check_data_savedfile(file_path, skip_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4code-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
