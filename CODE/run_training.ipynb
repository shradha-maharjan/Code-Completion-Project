{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9963f861",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\\nGPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\\nusing a masked language modeling (MLM) loss.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
    "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"\n",
    "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
    "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
    "using a masked language modeling (MLM) loss.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ff8d0",
   "metadata": {},
   "source": [
    "importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789702da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import re\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b920b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a57bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForMaskedLM,\n",
    "    RobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61adc636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d814ae0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59274824",
   "metadata": {},
   "source": [
    "Defining a class Args with various attributes initialized with default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2922b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.output_root = 'OUTPUTS'\n",
    "        self.model_type = 'roberta'\n",
    "        #self.early_stop = early_stop\n",
    "        self.line_by_line = True\n",
    "        #self.should_continue = should_continue\n",
    "        self.model_name_or_path = ''\n",
    "        self.mlm = True\n",
    "        self.mlm_probability = 0.2\n",
    "        self.tokenizer_name = 'roberta-base'\n",
    "        self.vocab_size = '50_000'\n",
    "        self.cache_dir = 'cache'\n",
    "        self.block_size = -1\n",
    "        self.do_train = True\n",
    "        self.do_eval = True\n",
    "        self.evaluate_during_training = True\n",
    "        self.per_gpu_train_batch_size = 2#wandb.config.batch_size\n",
    "        self.per_gpu_eval_batch_size = 2#wandb.config.batch_size\n",
    "        self.gradient_accumulation_steps = 4#wandb.config.gradient_accumulation_steps\n",
    "        self.learning_rate = 5e-5 #wandb.config.learning_rate\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.num_train_epochs = 1 #wandb.config.epochs\n",
    "        self.max_steps = -1\n",
    "        self.warmup_steps = 0\n",
    "        self.logging_steps = 500#logging_steps\n",
    "        self.save_steps = 500#logging_steps\n",
    "        self.save_total_limit = None\n",
    "        self.eval_all_checkpoints = False\n",
    "        self.no_cuda = False\n",
    "        self.overwrite_output_dir = True\n",
    "        self.seed = 42\n",
    "        self.fp16 = False\n",
    "        self.fp16_opt_level = \"O1\"\n",
    "        self.local_rank = -1\n",
    "        self.server_ip = \"\"\n",
    "        self.server_port = \"\"\n",
    "        # run.save()\n",
    "        # # self.name = run.name\n",
    "        # if self.should_continue:\n",
    "        self.output_dir = self.output_root\n",
    "        # else:\n",
    "        #     self.output_dir = self.output_root  + '/' + self.name\n",
    "\n",
    "\n",
    "args = Args()\n",
    "args.vocab_size = 50_000\n",
    "args.train_data_file = '/home/user1-selab3/shradha_test/roberta/roberta/DATASET/JAVA/TOKEN/RAW/training_masked_code-few'\n",
    "args.eval_data_file = '/home/user1-selab3/shradha_test/roberta/roberta/DATASET/JAVA/TOKEN/RAW/eval_masked_code-few'\n",
    "args.tokenizer_name = '/home/user1-selab3/shradha_test/roberta/roberta/CODE/TrainedTokenizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a718df",
   "metadata": {},
   "source": [
    "To checks whether args.local_rank is -1 or args.no_cuda is True. If either condition is met, it sets the device to CUDA if CUDA is available and args.no_cuda is not True, otherwise it sets the device to CPU. It also sets args.n_gpu to the number of available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bff1a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# if args.local_rank == -1 or args.no_cuda:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "# else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "#         torch.cuda.set_device(args.local_rank)\n",
    "#         device = torch.device(\"cuda\", args.local_rank)\n",
    "#         torch.distributed.init_process_group(backend=\"nccl\")\n",
    "#         args.n_gpu = 1\n",
    "args.device = device\n",
    "print(args.n_gpu)\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1af65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560c8a9",
   "metadata": {},
   "source": [
    "configures the logging format using basicConfig, specifying the format of the log messages, including the timestamp, log level, logger name, and the actual message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7003236e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02/2024 14:38:44 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 2, distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    args.local_rank,\n",
    "    device,\n",
    "    args.n_gpu,\n",
    "    bool(args.local_rank != -1),\n",
    "    args.fp16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f01835",
   "metadata": {},
   "source": [
    "Setting the seed for random number generation and ensuring reproducibility of results across different runs of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33a5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        \n",
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6fa40bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'> <class 'transformers.models.roberta.modeling_roberta.RobertaForMaskedLM'> <class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# Dictionary mapping model types to their corresponding classes\n",
    "MODEL_CLASSES = {\n",
    "    \"roberta\": (RobertaConfig, RobertaForMaskedLM, RobertaTokenizer),\n",
    "}\n",
    "\n",
    "# Retrieve the classes corresponding to the specified model type from MODEL_CLASSES\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "\n",
    "print(config_class, model_class, tokenizer_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429ac7c",
   "metadata": {},
   "source": [
    " Generating a configuration dictionary for a RoBERTa model and creating a RobertaConfig object using the provided arguments. Then, initializing a tokenizer using the specified tokenizer name and adjusting the block size based on the tokenizer's maximum model length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2201c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaTokenizer(name_or_path='/home/user1-selab3/shradha_test/roberta/roberta/CODE/TrainedTokenizer', vocab_size=261, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "# Define configuration parameters for RoBERTa model\n",
    "def get_config(args):\n",
    "    config = {\n",
    "        \"model_type\": \"roberta\",\n",
    "        \"attention_probs_dropout_prob\": 0.1,\n",
    "        \"hidden_act\": \"gelu\",\n",
    "        \"hidden_dropout_prob\": 0.3,\n",
    "        \"hidden_size\": 768, #wandb.config.hidden_size,\n",
    "        \"initializer_range\": 0.02,\n",
    "        \"num_attention_heads\": 16, #wandb.config.num_attention_heads,\n",
    "        \"num_hidden_layers\": 12, #wandb.config.num_hidden_layers,\n",
    "        \"vocab_size\": 1_130, #args.vocab_size,\n",
    "        \"intermediate_size\": 4_096, #wandb.config.intermediate_size,\n",
    "        \"max_position_embeddings\": 1024,\n",
    "        \"cache_dir\": '' #args.cache_dir\n",
    "    }\n",
    "# Return a RobertaConfig object initialized with the config parameters\n",
    "    return RobertaConfig(**config)\n",
    "# Get the configuration\n",
    "config = get_config(args)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
    "\n",
    "# Adjust block size based on tokenizer's maximum model length\n",
    "if args.block_size <= 0:\n",
    "    args.block_size = tokenizer.model_max_length\n",
    "    # Our input block size will be the max possible for the model\n",
    "else:\n",
    "    args.block_size = min(args.block_size, tokenizer.model_max_length)\n",
    "\n",
    "print(tokenizer)\n",
    "print(tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ff3687c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1aa2b9",
   "metadata": {},
   "source": [
    "If an exception occurs during model initialization, it is caught, and an error message is logged using the logger.error() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "446fe0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/02/2024 13:38:29 - INFO - __main__ -   Training new model from scratch\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Training new model from scratch\")\n",
    "try:\n",
    "    model = model_class(config=config)\n",
    "except Exception as e:\n",
    "    logger.error(f'{e} Configuration not correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78ca53",
   "metadata": {},
   "source": [
    " Adds special tokens to both the tokenizer and the model if they have not already been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6de6f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(263, 768)\n",
       "      (position_embeddings): Embedding(1024, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=263, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_special_tokens_(model, tokenizer):\n",
    "    \"\"\" Add special tokens to the tokenizer and the model if they have not already been added. \"\"\"\n",
    "    orig_num_tokens = len(tokenizer.encoder)\n",
    "    # Add special tokens to the tokenizer and get the number of tokens added\n",
    "    num_added_tokens = tokenizer.add_special_tokens({'additional_special_tokens': ['<z>', '<x>']}) # doesn't add if they are already there\n",
    "    # If tokens were added\n",
    "    if num_added_tokens > 0:\n",
    "        # Resize the token embeddings in the model to accommodate the newly added tokens\n",
    "        model.resize_token_embeddings(new_num_tokens=orig_num_tokens + num_added_tokens)\n",
    "\n",
    "# Add special tokens to the model and tokenizer\n",
    "add_special_tokens_(model, tokenizer)\n",
    "# Move the model to the specified device\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf2c28",
   "metadata": {},
   "source": [
    "To process a text file line by line using a Byte Level Byte Pair Encoding (ByteLevelBPETokenizer) tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb9b1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineByLineDatasetWithBPETokenizer(Dataset):\n",
    "    def __init__(self, file_path: str = None, tokenizer_path: str = None):\n",
    "        # Initialize the ByteLevelBPETokenizer using the provided tokenizer path\n",
    "        tokenizer = ByteLevelBPETokenizer(\n",
    "            tokenizer_path + \"/vocab.json\",\n",
    "            tokenizer_path + \"/merges.txt\",\n",
    "        )\n",
    "        # Set up special tokens for the tokenizer\n",
    "        tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        )\n",
    "        # Enable truncation of sequences to a maximum length of 512 tokens\n",
    "        tokenizer.enable_truncation(max_length=512)\n",
    "\n",
    "        # Initialize an empty list to store tokenized examples\n",
    "        self.examples = []\n",
    "\n",
    "        # Read lines from the input file\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            # Filter out empty lines and lines with only whitespace characters\n",
    "            lines = [line for line in lines if (len(line) > 0 and not line.isspace())]\n",
    "            # Tokenize each non-empty line and add the token IDs to self.examples\n",
    "            self.examples += [x.ids for x in tokenizer.encode_batch(lines)]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of examples in the dataset\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Return a single example from the dataset at the given index i\n",
    "        # Represented as a PyTorch tensor containing token IDs\n",
    "        # Weâ€™ll pad at the batch level.\n",
    "        return torch.tensor(self.examples[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8232b0",
   "metadata": {},
   "source": [
    " loading and caching examples from the training or evaluation data files using the LineByLineDatasetWithBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c38777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(args, evaluate=False):\n",
    "    # Determine the file path based on whether it's for evaluation or training\n",
    "    file_path = args.eval_data_file if evaluate else args.train_data_file\n",
    "    print(file_path)\n",
    "    print(args.tokenizer_name)\n",
    "    \n",
    "    # Return a LineByLineDatasetWithBPETokenizer object initialized with the file path and tokenizer name\n",
    "    return LineByLineDatasetWithBPETokenizer(file_path, args.tokenizer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8aa3e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user1-selab3/shradha_test/roberta/roberta/DATASET/JAVA/TOKEN/RAW/training_masked_code-few\n",
      "/home/user1-selab3/shradha_test/roberta/roberta/CODE/TrainedTokenizer\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_and_cache_examples(args, evaluate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0b77c",
   "metadata": {},
   "source": [
    "to retrieve and sort checkpoint paths based on certain criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21ab049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
    "    # Initialize an empty list to store checkpoint paths and their associated information\n",
    "    ordering_and_checkpoint_path = []\n",
    "\n",
    "    # Find all files matching the checkpoint pattern in the output directory\n",
    "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
    "\n",
    "    # Process each found checkpoint path\n",
    "    for path in glob_checkpoints:\n",
    "        if use_mtime:\n",
    "            # If use_mtime is True, append a tuple containing the modification time and path\n",
    "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
    "        else:\n",
    "            # If use_mtime is False, extract the checkpoint number and append a tuple containing it and path\n",
    "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
    "            if regex_match and regex_match.groups():\n",
    "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
    "\n",
    "    # Sort the list of checkpoint paths based on the criteria specified\n",
    "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
    "    \n",
    "    # Extract only the paths from the sorted list of tuples\n",
    "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
    "    \n",
    "    # Return the sorted list of checkpoint paths\n",
    "    return checkpoints_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294e68e",
   "metadata": {},
   "source": [
    "for managing checkpoints by deleting older checkpoints when the number of checkpoints exceeds a specified limit (args.save_total_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53114071",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
    "    # If save_total_limit is not set or is 0 or less, there's no need to rotate checkpoints\n",
    "    if not args.save_total_limit or args.save_total_limit <= 0:\n",
    "        return\n",
    "\n",
    "    # Get a sorted list of checkpoint paths\n",
    "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
    "    \n",
    "    # If the number of checkpoints is within the limit, there's no need to delete any checkpoints\n",
    "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
    "        return\n",
    "\n",
    "    # Calculate the number of checkpoints to delete\n",
    "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
    "    # Select the oldest checkpoints to delete\n",
    "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
    "    \n",
    "    # Delete the selected checkpoints\n",
    "    for checkpoint in checkpoints_to_be_deleted:\n",
    "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
    "        shutil.rmtree(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1871c58",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def decision(probability): #this function takes probability as input and returns true with probability\n",
    "    #It essentially simulates a random decision based on the provided probability. \n",
    "    return random.random() < probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ff7cc",
   "metadata": {},
   "source": [
    "read_masked_dataset function processes a batch of inputs and their corresponding labels to prepare them for training. It adjusts the lengths of inputs and labels to match the maximum length among them, and pads them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9056d990",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_masked_dataset(tokenizer: PreTrainedTokenizer, batch, labels_to_process) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    # The inputs are already masked in the training file\n",
    "    # Clone the batch of inputs to prevent modifying the original data\n",
    "    tmp_inputs = batch.clone()\n",
    "\n",
    "    # Process inputs\n",
    "    tmp_inputs_list = []\n",
    "    for input in tmp_inputs:\n",
    "        # Decode input, then re-encode it without special tokens\n",
    "        decoded_input = tokenizer.decode(input)\n",
    "        encoded_back = tokenizer.encode(decoded_input)[1:-1] # Removes the additional <s> and </s> added\n",
    "        tmp_inputs_list.append(encoded_back)\n",
    "\n",
    "    # Gets the maximum length between inputs and labels_lines\n",
    "    # We then need to adapt one or the other to have the same length through padding\n",
    "        \n",
    "    # # Calculate maximum length among inputs and labels\n",
    "    max_length_inputs = max([len(input) for input in tmp_inputs_list])\n",
    "    max_length_labels_lines = max([len(label) for label in labels_to_process])\n",
    "    max_length = max_length_inputs\n",
    "    if max_length_labels_lines > max_length_inputs:\n",
    "        max_length = max_length_labels_lines\n",
    "    print(max_length)\n",
    "    print(\"%%\")\n",
    "    print(tmp_inputs_list)\n",
    "\n",
    "    # Create the labels tensor\n",
    "    labels_to_convert_in_tensor = []\n",
    "\n",
    "    #It encodes each label using the tokenizer, excluding special tokens, and pads the encoded label to match the maximum length.\n",
    "    i = 0\n",
    "    while i < len(batch):\n",
    "        l1_tmp = tokenizer.encode(labels_to_process[i])\n",
    "        label_to_add = []\n",
    "        for token in l1_tmp:\n",
    "            if token != tokenizer.bos_token_id and token != tokenizer.eos_token_id:  # Remove special tokens\n",
    "                label_to_add.append(token)\n",
    "\n",
    "        j = len(label_to_add)\n",
    "        while j < max_length:\n",
    "            label_to_add.append(-100)  # we only compute loss for masked tokens\n",
    "            j += 1\n",
    "\n",
    "        labels_to_convert_in_tensor.append(label_to_add)\n",
    "        i += 1\n",
    "\n",
    "    labels = torch.as_tensor(labels_to_convert_in_tensor)\n",
    "\n",
    "    # Process inputs\n",
    "    inputs_to_convert = []\n",
    "    for input in tmp_inputs_list:\n",
    "        tmp_input = []\n",
    "        for token in input:\n",
    "            tmp_input.append(token)\n",
    " #It pads each input to match the maximum length, using the tokenizer's pad token ID.\n",
    "        i = len(tmp_input)\n",
    "        while i < max_length:\n",
    "            tmp_input.append(tokenizer.pad_token_id)\n",
    "            i += 1\n",
    "        inputs_to_convert.append(tmp_input)\n",
    "\n",
    "    inputs = torch.as_tensor(inputs_to_convert)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7da2df",
   "metadata": {},
   "source": [
    "reads masked instances but provides them as non-masked to the model. It essentially removes the masking and prepares the inputs for the model, where the model is expected to understand that if no masked tokens are present, nothing must be produced except for the <z> token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e4fd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the masked instances, but provide them as non-masked to the model\n",
    "# This is used in 10% of cases during training\n",
    "def get_non_masked_instances(tokenizer: PreTrainedTokenizer, batch, labels_to_process) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    tmp_inputs_list = []\n",
    "    i = 0\n",
    "    while i < len(batch):\n",
    "        # Decode the input, replace <x> tokens with labels, then re-encode the modified input\n",
    "        decoded_input = tokenizer.decode(batch[i]).replace('<x>',str(labels_to_process[i]).replace('<z>\\n',''))\n",
    "        encoded_back = tokenizer.encode(decoded_input)[1:-1]\n",
    "        tmp_inputs_list.append(encoded_back)\n",
    "        i += 1\n",
    "\n",
    "    # Gets the maximum length\n",
    "    max_length = max([len(input) for input in tmp_inputs_list])\n",
    "\n",
    "    inputs_to_convert = []\n",
    "    labels_to_convert = []\n",
    "    for input in tmp_inputs_list:\n",
    "        tmp_input = []\n",
    "        tmp_label = []\n",
    "        tmp_label.append(tokenizer.convert_tokens_to_ids('<z>'))\n",
    "        for token in input:\n",
    "            tmp_input.append(token)\n",
    "            tmp_label.append(-100)\n",
    "\n",
    "        del tmp_label[-1] #Accounts for the fact that tmp_label already contains <z>\n",
    "\n",
    "        i = len(tmp_input)\n",
    "        while i < max_length:\n",
    "            tmp_input.append(tokenizer.pad_token_id)\n",
    "            tmp_label.append(-100)\n",
    "            i += 1\n",
    "        labels_to_convert.append(tmp_label)\n",
    "        inputs_to_convert.append(tmp_input)\n",
    "\n",
    "    inputs = torch.as_tensor(inputs_to_convert)\n",
    "    labels = torch.as_tensor(labels_to_convert)\n",
    "\n",
    "    # We train the model to understand that if no masked tokens are present, nothing must be produced, only <z>\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b45317",
   "metadata": {},
   "source": [
    "read_perfect_predictions_from_file function reads the number of perfect predictions from a file. It searches for a specific pattern perfect_predictions = <number> in the content of the file and extracts the number following that pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85963f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_perfect_predictions_from_file(file_path):\n",
    "    # Open the file and read its content\n",
    "    with open(file_path) as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Compile a regular expression pattern to search for perfect predictions\n",
    "    p = re.compile('perfect_predictions = (.*?)\\n')\n",
    "    \n",
    "    # Search for the pattern in the content and extract the number\n",
    "    perfect_predictions = int(p.search(content).group(1))\n",
    "    \n",
    "    return perfect_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757a3de",
   "metadata": {},
   "source": [
    "This get_number_perfect_predictions function computes the number of perfect predictions made by a model on a given evaluation dataset. It compares the model's predictions with the ground truth labels and counts the instances where the prediction matches the label perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7079ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_perfect_predictions(model: PreTrainedModel, tokenizer: PreTrainedTokenizer, eval_data_file):\n",
    "    labels_file = str(eval_data_file).replace('masked_code_', 'mask_')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Inputs\n",
    "    with open(eval_data_file) as f:\n",
    "        inputs = f.readlines()\n",
    "    inputs = [x.strip() for x in inputs]\n",
    "\n",
    "    # Targets\n",
    "    with open(labels_file) as f:\n",
    "        targets = f.readlines()\n",
    "    targets = [x.strip() for x in targets]\n",
    "\n",
    "    n_perfect_predictions = 0\n",
    "    i = 0\n",
    "    while i < len(inputs):\n",
    "        input = inputs[i]\n",
    "        target = \"\".join(targets[i].split()).replace('<z>', '')\n",
    "\n",
    "        indexed_tokens = tokenizer.encode(input)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        tokens_tensor = tokens_tensor.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        predicted_sentence = []\n",
    "        for token in torch.argmax(predictions[0], 1).cpu().numpy():\n",
    "            if token != tokenizer.convert_tokens_to_ids('<z>'):\n",
    "                predicted_sentence.append(token)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        prediction = tokenizer.decode(predicted_sentence)\n",
    "        prediction = \"\".join(prediction.split())\n",
    "        if target == prediction:\n",
    "            n_perfect_predictions += 1\n",
    "        i += 1\n",
    "\n",
    "    return n_perfect_predictions, len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af4d71",
   "metadata": {},
   "source": [
    "to evaluate the performance of a trained model on an evaluation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93496fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, prefix=\"\") -> Dict:\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(args, evaluate=True)\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        os.makedirs(eval_output_dir, exist_ok=True)\n",
    "\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate\n",
    "    )\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "\n",
    "    labels_file = str(args.eval_data_file).replace('masked_code_', 'mask_')\n",
    "    labels_lines = [line.rstrip() for line in open(labels_file)]\n",
    "\n",
    "    step = 0\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        # Get the labels lines to process\n",
    "        start = step * len(batch)\n",
    "        end = start + len(batch) + 1\n",
    "        lables_to_process = labels_lines[start:end]\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        inputs, labels = read_masked_dataset(tokenizer, batch, lables_to_process)\n",
    "        inputs = inputs.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n",
    "            lm_loss = outputs[0]\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "    perfect_predictions, num_examples = get_number_perfect_predictions(model, tokenizer, args.eval_data_file)\n",
    "    result = {\"perplexity\": perplexity, \"loss\": eval_loss,\n",
    "              \"perfect_predictions\": perfect_predictions, \"total_eval_examples\": num_examples}\n",
    "\n",
    "    logger.log({'val_perplexity': perplexity, 'avg_val_loss': eval_loss})\n",
    "    logger.log({'perfect_predictions': perfect_predictions})\n",
    "    logger.log({'perfect_predictions_percentage': perfect_predictions / num_examples})\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results_\" + str(time.time()) + \".txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    if args.early_stop > 0:\n",
    "        # Early stop has been required by the user, check performance\n",
    "        eval_results_files = glob.glob(os.path.join(eval_output_dir, prefix,'eval_results_*.txt'))\n",
    "        eval_results_files.sort(key=lambda x: os.stat(os.path.join(eval_output_dir, x)).st_mtime)\n",
    "        if len(eval_results_files) > args.early_stop:\n",
    "            perfect_predictions_before = read_perfect_predictions_from_file(eval_results_files[len(eval_results_files)-(args.early_stop+1)])\n",
    "            if perfect_predictions <= perfect_predictions_before:\n",
    "                return None\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84219263",
   "metadata": {},
   "source": [
    "The train function is responsible for training the provided model using the provided training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31e2703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter()\n",
    "        \n",
    "    #sets the batch size for training.\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    #defines the data sampler for training.\n",
    "    train_sampler = SequentialSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    #Creates a DataLoader to iterate over the training dataset.\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate\n",
    "    )\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        #calculates the total number of training steps based on the number of epochs and gradient accumulation steps.\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    # initializes the AdamW optimizer with the defined parameters and  creates a linear scheduler with warmup for adjusting the learning rate during training.\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if (\n",
    "        args.model_name_or_path\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
    "        )\n",
    "\n",
    "    # Train!\n",
    "    #iterates over the training data for the specified number of epochs.\n",
    "    #Within each epoch, it iterates over batches of data.\n",
    "    #It handles cases where training is resumed from a checkpoint (global_step, epochs_trained, steps_trained_in_current_epoch).\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        args.train_batch_size\n",
    "        * args.gradient_accumulation_steps\n",
    "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
    "    )\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
    "        try:\n",
    "            # set global_step to gobal_step of last saved checkpoint from model path\n",
    "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
    "            global_step = int(checkpoint_suffix)\n",
    "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "\n",
    "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
    "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
    "        except ValueError:\n",
    "            logger.info(\"  Starting fine-tuning.\")\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "\n",
    "    model_to_resize = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
    "    model_to_resize.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
    "    )\n",
    "    set_seed(args)  # Added here for reproducibility\n",
    "\n",
    "    labels_file = str(args.train_data_file).replace('masked_code_','mask_')\n",
    "    labels_lines = [line.rstrip() for line in open(labels_file)]\n",
    "\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        # step is the count of the steps performed, batch contains the actual input data\n",
    "\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            # Get the labels lines to process\n",
    "            start = step * len(batch)\n",
    "            end = start + len(batch) + 1\n",
    "            lables_to_process = labels_lines[start:end]\n",
    "\n",
    "            # In 90% of cases, we used the inputs with the masked tokens\n",
    "            # In 10% of cases we don't mask any token\n",
    "            if decision(0.9):\n",
    "                inputs, labels = read_masked_dataset(tokenizer, batch, lables_to_process)\n",
    "            else:\n",
    "                inputs, labels = get_non_masked_instances(tokenizer, batch, lables_to_process)\n",
    "\n",
    "            inputs = inputs.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            print(\"$$\")\n",
    "            print(inputs.shape)\n",
    "            print(labels.shape)\n",
    "            print(\"**\")\n",
    "            model.train()\n",
    "            outputs = model(inputs, labels=labels) if args.mlm else model(inputs, labels=labels)\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                if args.fp16:\n",
    "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    if (\n",
    "                        args.local_rank == -1 and args.evaluate_during_training\n",
    "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        if results is None:\n",
    "                            print(\"Stopping condition reached, no improvement in evaluation set\")\n",
    "                            sys.exit(0)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    checkpoint_prefix = \"checkpoint\"\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    model_to_save = (\n",
    "                        model.module if hasattr(model, \"module\") else model\n",
    "                    )  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
    "\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07abdf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1-selab3/miniconda3/envs/myenv_python3_11/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "04/02/2024 13:48:33 - INFO - __main__ -   ***** Running training *****\n",
      "04/02/2024 13:48:33 - INFO - __main__ -     Num examples = 16906\n",
      "04/02/2024 13:48:33 - INFO - __main__ -     Num Epochs = 1\n",
      "04/02/2024 13:48:33 - INFO - __main__ -     Instantaneous batch size per GPU = 2\n",
      "04/02/2024 13:48:33 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "04/02/2024 13:48:33 - INFO - __main__ -     Gradient Accumulation steps = 4\n",
      "04/02/2024 13:48:33 - INFO - __main__ -     Total optimization steps = 2113\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 89, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 12, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 225, 67, 88, 76, 77, 87, 16, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 89, 87, 73, 86, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 37, 89, 88, 76, 49, 77, 82, 77, 81, 89, 81, 37, 72, 81, 77, 82, 52, 73, 86, 81, 77, 87, 87, 77, 83, 82, 16, 225, 54, 73, 81, 83, 88, 73, 41, 92, 71, 73, 84, 88, 77, 83, 82, 16, 225, 54, 89, 82, 88, 77, 81, 73, 42, 69, 89, 80, 88, 225, 261, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 65, 225, 84, 69, 86, 69, 81, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 22, 65, 31, 225, 84, 69, 86, 69, 81, 87, 63, 20, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 67, 88, 76, 77, 87, 6, 16, 225, 6, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 6, 16, 225, 67, 88, 76, 77, 87, 13, 31, 225, 84, 69, 86, 69, 81, 87, 63, 21, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 89, 87, 73, 86, 87, 6, 16, 225, 6, 55, 88, 86, 77, 82, 75, 63, 65, 6, 16, 225, 89, 87, 73, 86, 87, 13, 31, 225, 75, 73, 88, 59, 87, 71, 12, 13, 18, 77, 82, 90, 83, 79, 73, 12, 6, 57, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 6, 16, 225, 84, 69, 86, 69, 81, 87, 16, 225, 82, 89, 80, 80, 13, 31, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 89, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 12, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 225, 67, 88, 76, 77, 87, 16, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 89, 87, 73, 86, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 37, 89, 88, 76, 49, 77, 82, 77, 81, 89, 81, 37, 72, 81, 77, 82, 52, 73, 86, 81, 77, 87, 87, 77, 83, 82, 16, 225, 54, 73, 81, 83, 88, 73, 41, 92, 71, 73, 84, 88, 77, 83, 82, 16, 225, 54, 89, 82, 88, 77, 81, 73, 42, 69, 89, 80, 88, 16, 225, 57, 87, 73, 86, 50, 83, 88, 42, 83, 89, 82, 72, 225, 95, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 65, 225, 84, 69, 86, 69, 81, 87, 225, 261, 225, 84, 69, 86, 69, 81, 87, 63, 20, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 67, 88, 76, 77, 87, 6, 16, 225, 6, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 6, 16, 225, 67, 88, 76, 77, 87, 13, 31, 225, 84, 69, 86, 69, 81, 87, 63, 21, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 89, 87, 73, 86, 87, 6, 16, 225, 6, 55, 88, 86, 77, 82, 75, 63, 65, 6, 16, 225, 89, 87, 73, 86, 87, 13, 31, 225, 75, 73, 88, 59, 87, 71, 12, 13, 18, 77, 82, 90, 83, 79, 73, 12, 6, 57, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 6, 16, 225, 84, 69, 86, 69, 81, 87, 16, 225, 82, 89, 80, 80, 13, 31, 225, 97, 203, 2, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 372])\n",
      "torch.Size([2, 372])\n",
      "**\n",
      "379\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 89, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 12, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 225, 67, 88, 76, 77, 87, 16, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 89, 87, 73, 86, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 37, 89, 88, 76, 49, 77, 82, 77, 81, 89, 81, 37, 72, 81, 77, 82, 52, 73, 86, 81, 77, 87, 87, 77, 83, 82, 16, 225, 54, 73, 81, 83, 88, 73, 41, 92, 71, 73, 84, 88, 77, 83, 82, 16, 225, 54, 89, 82, 88, 77, 81, 73, 42, 69, 89, 80, 88, 16, 225, 57, 87, 73, 86, 50, 83, 88, 42, 83, 89, 82, 72, 225, 95, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 65, 225, 84, 69, 86, 69, 81, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 22, 65, 31, 225, 84, 69, 86, 69, 81, 87, 63, 20, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 67, 88, 76, 77, 87, 6, 16, 225, 261, 225, 84, 69, 86, 69, 81, 87, 63, 21, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 89, 87, 73, 86, 87, 6, 16, 225, 6, 55, 88, 86, 77, 82, 75, 63, 65, 6, 16, 225, 89, 87, 73, 86, 87, 13, 31, 225, 75, 73, 88, 59, 87, 71, 12, 13, 18, 77, 82, 90, 83, 79, 73, 12, 6, 57, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 6, 16, 225, 84, 69, 86, 69, 81, 87, 16, 225, 82, 89, 80, 80, 13, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 89, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 12, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 225, 67, 88, 76, 77, 87, 16, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 89, 87, 73, 86, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 37, 89, 88, 76, 49, 77, 82, 77, 81, 89, 81, 37, 72, 81, 77, 82, 52, 73, 86, 81, 77, 87, 87, 77, 83, 82, 16, 225, 54, 73, 81, 83, 88, 73, 41, 92, 71, 73, 84, 88, 77, 83, 82, 16, 225, 54, 89, 82, 88, 77, 81, 73, 42, 69, 89, 80, 88, 16, 225, 57, 87, 73, 86, 50, 83, 88, 42, 83, 89, 82, 72, 225, 95, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 65, 225, 84, 69, 86, 69, 81, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 22, 65, 31, 225, 84, 69, 86, 69, 81, 87, 63, 20, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 67, 88, 76, 77, 87, 6, 16, 225, 6, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 6, 16, 225, 67, 88, 76, 77, 87, 13, 31, 225, 84, 69, 86, 69, 81, 87, 63, 21, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 89, 87, 73, 86, 87, 6, 16, 225, 6, 55, 88, 86, 77, 82, 75, 63, 65, 6, 225, 261, 225, 75, 73, 88, 59, 87, 71, 12, 13, 18, 77, 82, 90, 83, 79, 73, 12, 6, 57, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 6, 16, 225, 84, 69, 86, 69, 81, 87, 16, 225, 82, 89, 80, 80, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 379])\n",
      "torch.Size([2, 379])\n",
      "**\n",
      "473\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 89, 84, 72, 69, 88, 73, 48, 83, 71, 79, 72, 83, 91, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 87, 12, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 225, 67, 88, 76, 77, 87, 16, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 89, 87, 73, 86, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 37, 89, 88, 76, 49, 77, 82, 77, 81, 89, 81, 37, 72, 81, 77, 82, 52, 73, 86, 81, 77, 87, 87, 77, 83, 82, 16, 225, 54, 73, 81, 83, 88, 73, 41, 92, 71, 73, 84, 88, 77, 83, 82, 16, 225, 54, 89, 82, 88, 77, 81, 73, 42, 69, 89, 80, 88, 16, 225, 57, 87, 73, 86, 50, 83, 88, 42, 83, 89, 82, 72, 225, 95, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 65, 225, 84, 69, 86, 69, 81, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 63, 22, 65, 31, 225, 84, 69, 86, 69, 81, 87, 63, 20, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 67, 88, 76, 77, 87, 6, 16, 225, 6, 49, 69, 82, 69, 75, 73, 72, 51, 70, 78, 73, 71, 88, 54, 73, 74, 73, 86, 73, 82, 71, 73, 6, 16, 225, 67, 88, 76, 77, 87, 13, 31, 225, 84, 69, 86, 69, 81, 87, 63, 21, 65, 225, 33, 225, 82, 73, 91, 225, 37, 86, 75, 89, 81, 73, 82, 88, 12, 6, 89, 87, 73, 86, 87, 6, 16, 225, 6, 55, 88, 86, 77, 82, 75, 63, 65, 6, 16, 225, 89, 87, 73, 86, 87, 13, 31, 225, 75, 73, 88, 59, 87, 71, 12, 13, 18, 77, 82, 90, 83, 79, 73, 12, 225, 261, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 261, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 473])\n",
      "torch.Size([2, 473])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 225, 261, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 225, 261, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2, 1]]\n",
      "$$\n",
      "torch.Size([2, 474])\n",
      "torch.Size([2, 474])\n",
      "**\n",
      "472\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 261, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 225, 261, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 472])\n",
      "torch.Size([2, 472])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 225, 261, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2, 1, 1, 1], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 261, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 473])\n",
      "torch.Size([2, 473])\n",
      "**\n",
      "474\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 225, 261, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 225, 261, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 474])\n",
      "torch.Size([2, 474])\n",
      "**\n",
      "467\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 261, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 75, 73, 88, 55, 77, 82, 75, 80, 73, 52, 86, 83, 78, 73, 71, 88, 48, 77, 87, 88, 12, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 31, 225, 97, 203, 2], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 37, 75, 73, 82, 88, 52, 86, 83, 78, 73, 71, 88, 45, 82, 74, 83, 34, 225, 71, 83, 80, 80, 73, 71, 88, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 55, 88, 86, 77, 82, 75, 225, 74, 83, 80, 72, 73, 86, 13, 225, 95, 225, 77, 74, 225, 12, 5, 77, 82, 71, 80, 89, 72, 73, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 13, 95, 225, 72, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 74, 77, 82, 72, 40, 73, 90, 40, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 12, 74, 83, 80, 72, 73, 86, 13, 31, 225, 97, 225, 42, 77, 80, 73, 225, 93, 69, 86, 82, 48, 83, 71, 79, 225, 33, 225, 82, 73, 91, 225, 42, 77, 80, 73, 12, 74, 83, 80, 72, 73, 86, 225, 15, 225, 74, 77, 80, 73, 55, 73, 84, 69, 86, 69, 88, 83, 86, 225, 15, 225, 61, 37, 54, 50, 67, 48, 51, 39, 47, 13, 31, 225, 70, 83, 83, 80, 73, 69, 82, 225, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 225, 33, 225, 93, 69, 86, 82, 48, 83, 71, 79, 18, 77, 87, 42, 77, 80, 73, 12, 13, 31, 225, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 32, 40, 73, 84, 73, 82, 72, 73, 82, 71, 93, 45, 82, 74, 83, 34, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 82, 73, 91, 225, 37, 86, 86, 69, 93, 48, 77, 87, 88, 32, 34, 12, 13, 31, 225, 77, 74, 225, 12, 93, 69, 86, 82, 48, 83, 71, 79, 42, 83, 89, 82, 72, 13, 95, 225, 72, 73, 84, 73, 82, 72, 73, 82, 71, 77, 73, 87, 225, 33, 225, 84, 69, 86, 87, 73, 61, 69, 86, 82, 48, 83, 71, 79, 12, 93, 69, 86, 82, 48, 83, 71, 79, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 82, 84, 81, 48, 87, 42, 69, 77, 80, 89, 86, 73, 55, 88, 69, 88, 89, 87, 225, 33, 225, 88, 86, 89, 73, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 467])\n",
      "torch.Size([2, 467])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 261, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 12, 13, 13, 31, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 12, 13, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 71, 83, 81, 84, 80, 73, 88, 73, 18, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 12, 13, 13, 31, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 69, 84, 84, 73, 82, 72, 56, 83, 38, 89, 74, 74, 73, 86, 12, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 70, 89, 74, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 225, 261, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 12, 13, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 71, 83, 81, 84, 80, 73, 88, 73, 18, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 12, 13, 13, 31, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 301])\n",
      "torch.Size([2, 301])\n",
      "**\n",
      "302\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 69, 84, 84, 73, 82, 72, 56, 83, 38, 89, 74, 74, 73, 86, 12, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 70, 89, 74, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 12, 13, 13, 31, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 225, 261, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 71, 83, 81, 84, 80, 73, 88, 73, 18, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 12, 13, 13, 31, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 31, 225, 97, 203, 2], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 69, 84, 84, 73, 82, 72, 56, 83, 38, 89, 74, 74, 73, 86, 12, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 70, 89, 74, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 12, 13, 13, 31, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 12, 13, 13, 225, 95, 225, 70, 89, 74, 225, 261, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 12, 13, 13, 31, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 302])\n",
      "torch.Size([2, 302])\n",
      "**\n",
      "303\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 69, 84, 84, 73, 82, 72, 56, 83, 38, 89, 74, 74, 73, 86, 12, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 70, 89, 74, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 12, 13, 13, 31, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 12, 13, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 71, 83, 81, 84, 80, 73, 88, 73, 18, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 261, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 12, 13, 13, 31, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 31, 225, 97, 203, 2], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 69, 84, 84, 73, 82, 72, 56, 83, 38, 89, 74, 74, 73, 86, 12, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 70, 89, 74, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 12, 13, 13, 31, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 12, 13, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 71, 83, 81, 84, 80, 73, 88, 73, 18, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 225, 261, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 31, 225, 97, 203, 2, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 303])\n",
      "torch.Size([2, 303])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 69, 84, 84, 73, 82, 72, 56, 83, 38, 89, 74, 74, 73, 86, 12, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 70, 89, 74, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 12, 13, 13, 31, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 12, 13, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 71, 83, 81, 84, 80, 73, 88, 73, 18, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 12, 13, 13, 31, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 225, 261, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 31, 225, 97, 203, 2, 1], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 69, 84, 84, 73, 82, 72, 56, 83, 38, 89, 74, 74, 73, 86, 12, 55, 88, 86, 77, 82, 75, 38, 89, 77, 80, 72, 73, 86, 225, 70, 89, 74, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 87, 89, 84, 73, 86, 18, 75, 73, 88, 56, 69, 87, 79, 12, 13, 13, 31, 225, 77, 74, 225, 12, 77, 87, 39, 83, 81, 84, 80, 73, 88, 73, 12, 13, 13, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 71, 83, 81, 84, 80, 73, 88, 73, 18, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 225, 7, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 52, 86, 83, 71, 73, 87, 87, 73, 72, 12, 13, 15, 21, 13, 18, 69, 84, 84, 73, 82, 72, 12, 11, 19, 11, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 56, 83, 88, 69, 80, 12, 13, 13, 31, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 6, 30, 225, 6, 13, 18, 69, 84, 84, 73, 82, 72, 12, 75, 73, 88, 55, 88, 73, 84, 56, 77, 88, 80, 73, 12, 13, 13, 31, 225, 97, 225, 70, 89, 74, 18, 69, 84, 84, 73, 82, 72, 12, 11, 64, 82, 11, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 89, 74, 225, 261, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 304])\n",
      "torch.Size([2, 304])\n",
      "**\n",
      "200\n",
      "%%\n",
      "[[0, 36, 56, 86, 77, 90, 77, 69, 80, 225, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 71, 76, 69, 86, 63, 65, 225, 75, 73, 82, 73, 86, 69, 88, 73, 54, 69, 82, 72, 83, 81, 225, 261, 225, 71, 76, 69, 86, 63, 65, 225, 84, 69, 87, 87, 225, 33, 225, 82, 73, 91, 225, 71, 76, 69, 86, 63, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 65, 31, 225, 74, 83, 86, 225, 12, 77, 82, 88, 225, 77, 225, 33, 225, 20, 31, 225, 77, 225, 32, 225, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 31, 225, 77, 15, 15, 13, 225, 84, 69, 87, 87, 63, 77, 65, 225, 33, 225, 39, 44, 37, 54, 67, 55, 41, 56, 63, 86, 69, 82, 72, 18, 82, 73, 92, 88, 45, 82, 88, 12, 39, 44, 37, 54, 67, 55, 41, 56, 18, 80, 73, 82, 75, 88, 76, 13, 65, 31, 225, 86, 73, 88, 89, 86, 82, 225, 84, 69, 87, 87, 31, 225, 97, 203, 2, 1, 1], [0, 36, 56, 86, 77, 90, 77, 69, 80, 225, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 71, 76, 69, 86, 63, 65, 225, 75, 73, 82, 73, 86, 69, 88, 73, 54, 69, 82, 72, 83, 81, 12, 13, 225, 95, 225, 71, 76, 69, 86, 63, 65, 225, 84, 69, 87, 87, 225, 33, 225, 82, 73, 91, 225, 71, 76, 69, 86, 63, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 225, 261, 225, 74, 83, 86, 225, 12, 77, 82, 88, 225, 77, 225, 33, 225, 20, 31, 225, 77, 225, 32, 225, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 31, 225, 77, 15, 15, 13, 225, 84, 69, 87, 87, 63, 77, 65, 225, 33, 225, 39, 44, 37, 54, 67, 55, 41, 56, 63, 86, 69, 82, 72, 18, 82, 73, 92, 88, 45, 82, 88, 12, 39, 44, 37, 54, 67, 55, 41, 56, 18, 80, 73, 82, 75, 88, 76, 13, 65, 31, 225, 86, 73, 88, 89, 86, 82, 225, 84, 69, 87, 87, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 200])\n",
      "torch.Size([2, 200])\n",
      "**\n",
      "348\n",
      "%%\n",
      "[[0, 36, 56, 86, 77, 90, 77, 69, 80, 225, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 71, 76, 69, 86, 63, 65, 225, 75, 73, 82, 73, 86, 69, 88, 73, 54, 69, 82, 72, 83, 81, 12, 13, 225, 95, 225, 71, 76, 69, 86, 63, 65, 225, 84, 69, 87, 87, 225, 33, 225, 82, 73, 91, 225, 71, 76, 69, 86, 63, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 65, 31, 225, 74, 83, 86, 225, 12, 77, 82, 88, 225, 77, 225, 33, 225, 20, 31, 225, 77, 225, 32, 225, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 225, 261, 225, 84, 69, 87, 87, 63, 77, 65, 225, 33, 225, 39, 44, 37, 54, 67, 55, 41, 56, 63, 86, 69, 82, 72, 18, 82, 73, 92, 88, 45, 82, 88, 12, 39, 44, 37, 54, 67, 55, 41, 56, 18, 80, 73, 82, 75, 88, 76, 13, 65, 31, 225, 86, 73, 88, 89, 86, 82, 225, 84, 69, 87, 87, 31, 225, 97, 203, 2], [0, 36, 56, 86, 77, 90, 77, 69, 80, 225, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 71, 76, 69, 86, 63, 65, 225, 75, 73, 82, 73, 86, 69, 88, 73, 54, 69, 82, 72, 83, 81, 12, 13, 225, 95, 225, 71, 76, 69, 86, 63, 65, 225, 84, 69, 87, 87, 225, 33, 225, 82, 73, 91, 225, 71, 76, 69, 86, 63, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 65, 31, 225, 74, 83, 86, 225, 12, 77, 82, 88, 225, 77, 225, 33, 225, 20, 31, 225, 77, 225, 32, 225, 52, 37, 55, 55, 59, 51, 54, 40, 67, 48, 41, 50, 43, 56, 44, 31, 225, 77, 15, 15, 13, 225, 84, 69, 87, 87, 63, 77, 65, 225, 33, 225, 39, 44, 37, 54, 67, 55, 41, 56, 63, 86, 69, 82, 72, 18, 82, 73, 92, 88, 45, 82, 88, 12, 39, 44, 37, 54, 67, 55, 41, 56, 18, 80, 73, 82, 75, 88, 76, 13, 65, 31, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 348])\n",
      "torch.Size([2, 348])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 39, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 225, 71, 86, 73, 69, 88, 73, 12, 80, 83, 82, 75, 225, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 45, 72, 13, 225, 95, 225, 39, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 225, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 225, 33, 225, 82, 73, 91, 225, 39, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 45, 81, 84, 80, 12, 13, 31, 225, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 18, 87, 73, 88, 50, 73, 91, 12, 88, 86, 89, 73, 13, 31, 225, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 18, 87, 73, 88, 52, 86, 77, 81, 69, 86, 93, 47, 73, 93, 12, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 45, 72, 13, 31, 225, 55, 88, 86, 77, 82, 75, 225, 225, 261, 225, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 18, 87, 73, 88, 57, 89, 77, 72, 12, 89, 89, 77, 72, 13, 31, 225, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 18, 87, 73, 88, 39, 83, 81, 84, 69, 82, 93, 45, 72, 12, 71, 83, 81, 84, 69, 82, 93, 52, 86, 83, 90, 77, 72, 73, 86, 18, 75, 73, 88, 39, 83, 81, 84, 69, 82, 93, 45, 72, 12, 13, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 71, 83, 81, 81, 73, 86, 71, 73, 39, 89, 86, 86, 73, 82, 71, 93, 31, 225, 97, 203, 2], [0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 261, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 356])\n",
      "torch.Size([2, 356])\n",
      "**\n",
      "360\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 261, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 261, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 360])\n",
      "torch.Size([2, 360])\n",
      "**\n",
      "360\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 225, 261, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 261, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 360])\n",
      "torch.Size([2, 360])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 261, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 225, 261, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 360])\n",
      "torch.Size([2, 360])\n",
      "**\n",
      "356\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 261, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2], [0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 261, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 89, 86, 80, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 356])\n",
      "torch.Size([2, 356])\n",
      "**\n",
      "357\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 57, 54, 48, 225, 71, 86, 73, 69, 88, 73, 57, 54, 48, 12, 74, 77, 82, 69, 80, 225, 55, 88, 86, 77, 82, 75, 225, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 57, 54, 48, 225, 89, 86, 80, 31, 225, 88, 86, 93, 225, 95, 225, 89, 86, 80, 225, 33, 225, 37, 71, 71, 73, 87, 87, 39, 83, 82, 88, 86, 83, 80, 80, 73, 86, 18, 72, 83, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 12, 82, 73, 91, 225, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 41, 92, 71, 73, 84, 88, 77, 83, 82, 37, 71, 88, 77, 83, 82, 32, 57, 54, 48, 34, 12, 13, 225, 95, 225, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 57, 54, 48, 225, 86, 89, 82, 12, 13, 225, 88, 76, 86, 83, 91, 87, 225, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 82, 73, 91, 225, 57, 54, 48, 12, 89, 86, 80, 55, 88, 86, 77, 82, 75, 13, 31, 225, 97, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 52, 86, 77, 90, 77, 80, 73, 75, 73, 72, 37, 71, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 12, 49, 69, 80, 74, 83, 86, 81, 73, 72, 57, 54, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 13, 225, 73, 18, 75, 73, 88, 39, 69, 89, 87, 73, 12, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 203, 2], [0, 84, 86, 77, 90, 69, 88, 73, 225, 90, 83, 77, 72, 225, 72, 73, 80, 73, 88, 73, 52, 86, 73, 90, 77, 83, 89, 87, 12, 55, 88, 86, 77, 82, 75, 225, 88, 73, 92, 88, 225, 261, 225, 55, 53, 48, 77, 88, 73, 51, 84, 73, 82, 44, 73, 80, 84, 73, 86, 225, 76, 73, 80, 84, 73, 86, 225, 33, 225, 82, 73, 91, 225, 40, 38, 44, 73, 80, 84, 73, 86, 12, 69, 71, 88, 77, 90, 77, 88, 93, 13, 31, 225, 88, 86, 93, 225, 12, 55, 53, 48, 77, 88, 73, 40, 69, 88, 69, 70, 69, 87, 73, 225, 72, 70, 225, 33, 225, 76, 73, 80, 84, 73, 86, 18, 75, 73, 88, 59, 86, 77, 88, 69, 70, 80, 73, 40, 69, 88, 69, 70, 69, 87, 73, 12, 13, 13, 225, 95, 225, 72, 70, 18, 72, 73, 80, 73, 88, 73, 12, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 37, 38, 48, 41, 67, 50, 37, 49, 41, 16, 225, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 41, 60, 56, 67, 39, 51, 48, 225, 15, 225, 6, 33, 35, 6, 16, 225, 82, 73, 91, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 95, 225, 88, 73, 92, 88, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 55, 53, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 87, 85, 80, 73, 13, 225, 95, 225, 48, 83, 75, 18, 91, 12, 56, 37, 43, 16, 225, 87, 85, 80, 73, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 357])\n",
      "torch.Size([2, 357])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 90, 83, 77, 72, 225, 72, 73, 80, 73, 88, 73, 52, 86, 73, 90, 77, 83, 89, 87, 12, 55, 88, 86, 77, 82, 75, 225, 88, 73, 92, 88, 13, 225, 95, 225, 55, 53, 48, 77, 88, 73, 51, 84, 73, 82, 44, 73, 80, 84, 73, 86, 225, 76, 73, 80, 84, 73, 86, 225, 33, 225, 82, 73, 91, 225, 261, 225, 88, 86, 93, 225, 12, 55, 53, 48, 77, 88, 73, 40, 69, 88, 69, 70, 69, 87, 73, 225, 72, 70, 225, 33, 225, 76, 73, 80, 84, 73, 86, 18, 75, 73, 88, 59, 86, 77, 88, 69, 70, 80, 73, 40, 69, 88, 69, 70, 69, 87, 73, 12, 13, 13, 225, 95, 225, 72, 70, 18, 72, 73, 80, 73, 88, 73, 12, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 37, 38, 48, 41, 67, 50, 37, 49, 41, 16, 225, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 41, 60, 56, 67, 39, 51, 48, 225, 15, 225, 6, 33, 35, 6, 16, 225, 82, 73, 91, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 95, 225, 88, 73, 92, 88, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 55, 53, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 87, 85, 80, 73, 13, 225, 95, 225, 48, 83, 75, 18, 91, 12, 56, 37, 43, 16, 225, 87, 85, 80, 73, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 90, 83, 77, 72, 225, 72, 73, 80, 73, 88, 73, 52, 86, 73, 90, 77, 83, 89, 87, 12, 55, 88, 86, 77, 82, 75, 225, 88, 73, 92, 88, 13, 225, 95, 225, 55, 53, 48, 77, 88, 73, 51, 84, 73, 82, 44, 73, 80, 84, 73, 86, 225, 76, 73, 80, 84, 73, 86, 225, 33, 225, 82, 73, 91, 225, 40, 38, 44, 73, 80, 84, 73, 86, 12, 69, 71, 88, 77, 90, 77, 88, 93, 13, 31, 225, 88, 86, 93, 225, 12, 55, 53, 48, 77, 88, 73, 40, 69, 88, 69, 70, 69, 87, 73, 225, 72, 70, 225, 33, 225, 76, 73, 80, 84, 73, 86, 18, 75, 73, 88, 59, 86, 77, 88, 69, 70, 80, 73, 40, 69, 88, 69, 70, 69, 87, 73, 12, 13, 13, 225, 95, 225, 72, 70, 18, 72, 73, 80, 73, 88, 73, 12, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 37, 38, 48, 41, 67, 50, 37, 49, 41, 16, 225, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 41, 60, 56, 67, 39, 51, 48, 225, 15, 225, 6, 33, 35, 6, 16, 225, 82, 73, 91, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 225, 261, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 55, 53, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 87, 85, 80, 73, 13, 225, 95, 225, 48, 83, 75, 18, 91, 12, 56, 37, 43, 16, 225, 87, 85, 80, 73, 13, 31, 225, 97, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 278])\n",
      "torch.Size([2, 278])\n",
      "**\n",
      "279\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 90, 83, 77, 72, 225, 72, 73, 80, 73, 88, 73, 52, 86, 73, 90, 77, 83, 89, 87, 12, 55, 88, 86, 77, 82, 75, 225, 88, 73, 92, 88, 13, 225, 95, 225, 55, 53, 48, 77, 88, 73, 51, 84, 73, 82, 44, 73, 80, 84, 73, 86, 225, 76, 73, 80, 84, 73, 86, 225, 33, 225, 82, 73, 91, 225, 40, 38, 44, 73, 80, 84, 73, 86, 12, 69, 71, 88, 77, 90, 77, 88, 93, 13, 31, 225, 88, 86, 93, 225, 12, 55, 53, 48, 77, 88, 73, 40, 69, 88, 69, 70, 69, 87, 73, 225, 72, 70, 225, 33, 225, 76, 73, 80, 84, 73, 86, 18, 75, 73, 88, 59, 86, 77, 88, 69, 70, 80, 73, 40, 69, 88, 69, 70, 69, 87, 73, 12, 13, 13, 225, 95, 225, 72, 70, 18, 72, 73, 80, 73, 88, 73, 12, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 37, 38, 48, 41, 67, 50, 37, 49, 41, 16, 225, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 41, 60, 56, 67, 39, 51, 48, 225, 15, 225, 6, 33, 35, 6, 16, 225, 82, 73, 91, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 95, 225, 88, 73, 92, 88, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 55, 53, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 261, 225, 48, 83, 75, 18, 91, 12, 56, 37, 43, 16, 225, 87, 85, 80, 73, 13, 31, 225, 97, 225, 97, 203, 2], [0, 84, 86, 77, 90, 69, 88, 73, 225, 90, 83, 77, 72, 225, 72, 73, 80, 73, 88, 73, 52, 86, 73, 90, 77, 83, 89, 87, 12, 55, 88, 86, 77, 82, 75, 225, 88, 73, 92, 88, 13, 225, 95, 225, 55, 53, 48, 77, 88, 73, 51, 84, 73, 82, 44, 73, 80, 84, 73, 86, 225, 76, 73, 80, 84, 73, 86, 225, 33, 225, 82, 73, 91, 225, 40, 38, 44, 73, 80, 84, 73, 86, 12, 69, 71, 88, 77, 90, 77, 88, 93, 13, 31, 225, 88, 86, 93, 225, 12, 55, 53, 48, 77, 88, 73, 40, 69, 88, 69, 70, 69, 87, 73, 225, 72, 70, 225, 33, 225, 76, 73, 80, 84, 73, 86, 18, 75, 73, 88, 59, 86, 77, 88, 69, 70, 80, 73, 40, 69, 88, 69, 70, 69, 87, 73, 12, 13, 13, 225, 95, 225, 72, 70, 18, 72, 73, 80, 73, 88, 73, 12, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 37, 38, 48, 41, 67, 50, 37, 49, 41, 16, 225, 40, 38, 44, 73, 80, 84, 73, 86, 18, 56, 41, 60, 56, 67, 39, 51, 48, 225, 15, 225, 6, 33, 35, 6, 16, 225, 82, 73, 91, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 95, 225, 88, 73, 92, 88, 225, 97, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 55, 53, 48, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 87, 85, 80, 73, 13, 225, 95, 225, 48, 83, 75, 18, 91, 12, 56, 37, 43, 225, 261, 225, 97, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 279])\n",
      "torch.Size([2, 279])\n",
      "**\n",
      "211\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 74, 77, 80, 88, 73, 86, 12, 55, 88, 86, 77, 82, 75, 225, 57, 54, 48, 16, 225, 225, 261, 225, 52, 69, 86, 87, 73, 54, 73, 87, 89, 80, 88, 225, 84, 69, 86, 87, 73, 13, 225, 95, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 88, 69, 75, 87, 225, 33, 225, 71, 83, 80, 80, 73, 71, 88, 77, 83, 82, 87, 18, 88, 69, 75, 12, 57, 54, 48, 13, 31, 225, 77, 74, 225, 12, 88, 69, 75, 87, 18, 80, 73, 82, 75, 88, 76, 225, 34, 225, 20, 13, 225, 95, 225, 84, 69, 86, 87, 73, 18, 75, 73, 88, 12, 57, 54, 48, 13, 18, 75, 73, 88, 49, 73, 88, 69, 72, 69, 88, 69, 12, 13, 18, 87, 73, 88, 58, 69, 80, 89, 73, 87, 12, 79, 73, 93, 16, 225, 88, 69, 75, 87, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 74, 77, 80, 88, 73, 86, 12, 55, 88, 86, 77, 82, 75, 225, 57, 54, 48, 16, 225, 70, 93, 88, 73, 63, 65, 225, 71, 83, 82, 88, 73, 82, 88, 16, 225, 40, 83, 71, 89, 81, 73, 82, 88, 42, 86, 69, 75, 81, 73, 82, 88, 225, 72, 83, 71, 16, 225, 52, 69, 86, 87, 73, 54, 73, 87, 89, 80, 88, 225, 261, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 88, 69, 75, 87, 225, 33, 225, 71, 83, 80, 80, 73, 71, 88, 77, 83, 82, 87, 18, 88, 69, 75, 12, 57, 54, 48, 13, 31, 225, 77, 74, 225, 12, 88, 69, 75, 87, 18, 80, 73, 82, 75, 88, 76, 225, 34, 225, 20, 13, 225, 95, 225, 84, 69, 86, 87, 73, 18, 75, 73, 88, 12, 57, 54, 48, 13, 18, 75, 73, 88, 49, 73, 88, 69, 72, 69, 88, 69, 12, 13, 18, 87, 73, 88, 58, 69, 80, 89, 73, 87, 12, 79, 73, 93, 16, 225, 88, 69, 75, 87, 13, 31, 225, 97, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 211])\n",
      "torch.Size([2, 211])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 74, 77, 80, 88, 73, 86, 12, 55, 88, 86, 77, 82, 75, 225, 57, 54, 48, 16, 225, 70, 93, 88, 73, 63, 65, 225, 71, 83, 82, 88, 73, 82, 88, 16, 225, 40, 83, 71, 89, 81, 73, 82, 88, 42, 86, 69, 75, 81, 73, 82, 88, 225, 72, 83, 71, 16, 225, 52, 69, 86, 87, 73, 54, 73, 87, 89, 80, 88, 225, 84, 69, 86, 87, 73, 13, 225, 95, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 88, 69, 75, 87, 225, 33, 225, 71, 83, 80, 80, 73, 71, 88, 77, 83, 82, 87, 225, 261, 225, 77, 74, 225, 12, 88, 69, 75, 87, 18, 80, 73, 82, 75, 88, 76, 225, 34, 225, 20, 13, 225, 95, 225, 84, 69, 86, 87, 73, 18, 75, 73, 88, 12, 57, 54, 48, 13, 18, 75, 73, 88, 49, 73, 88, 69, 72, 69, 88, 69, 12, 13, 18, 87, 73, 88, 58, 69, 80, 89, 73, 87, 12, 79, 73, 93, 16, 225, 88, 69, 75, 87, 13, 31, 225, 97, 225, 97, 203, 2], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 74, 77, 80, 88, 73, 86, 12, 55, 88, 86, 77, 82, 75, 225, 57, 54, 48, 16, 225, 70, 93, 88, 73, 63, 65, 225, 71, 83, 82, 88, 73, 82, 88, 16, 225, 40, 83, 71, 89, 81, 73, 82, 88, 42, 86, 69, 75, 81, 73, 82, 88, 225, 72, 83, 71, 16, 225, 52, 69, 86, 87, 73, 54, 73, 87, 89, 80, 88, 225, 84, 69, 86, 87, 73, 13, 225, 95, 225, 55, 88, 86, 77, 82, 75, 63, 65, 225, 88, 69, 75, 87, 225, 33, 225, 71, 83, 80, 80, 73, 71, 88, 77, 83, 82, 87, 18, 88, 69, 75, 12, 57, 54, 48, 13, 31, 225, 77, 74, 225, 12, 225, 261, 225, 84, 69, 86, 87, 73, 18, 75, 73, 88, 12, 57, 54, 48, 13, 18, 75, 73, 88, 49, 73, 88, 69, 72, 69, 88, 69, 12, 13, 18, 87, 73, 88, 58, 69, 80, 89, 73, 87, 12, 79, 73, 93, 16, 225, 88, 69, 75, 87, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 210])\n",
      "torch.Size([2, 210])\n",
      "**\n",
      "$$\n",
      "torch.Size([2, 412])\n",
      "torch.Size([2, 412])\n",
      "**\n",
      "173\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 49, 69, 84, 51, 70, 78, 73, 71, 88, 49, 69, 84, 225, 76, 69, 90, 77, 82, 75, 12, 225, 55, 88, 86, 77, 82, 75, 225, 74, 77, 73, 80, 72, 21, 16, 225, 51, 70, 78, 73, 71, 88, 225, 261, 225, 77, 74, 12, 83, 70, 78, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 31, 225, 83, 70, 78, 225, 33, 225, 49, 69, 84, 51, 70, 78, 73, 71, 88, 57, 88, 77, 80, 87, 18, 76, 69, 90, 77, 82, 75, 12, 12, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 13, 83, 70, 78, 16, 225, 74, 77, 73, 80, 72, 21, 16, 225, 90, 69, 80, 89, 73, 21, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 31, 225, 97, 203, 2], [0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 49, 69, 84, 51, 70, 78, 73, 71, 88, 49, 69, 84, 225, 76, 69, 90, 77, 82, 75, 12, 225, 55, 88, 86, 77, 82, 75, 225, 74, 77, 73, 80, 72, 21, 16, 225, 51, 70, 78, 73, 71, 88, 225, 90, 69, 80, 89, 73, 21, 13, 225, 95, 225, 77, 74, 12, 83, 70, 78, 225, 33, 33, 225, 82, 89, 80, 80, 225, 261, 225, 83, 70, 78, 225, 33, 225, 49, 69, 84, 51, 70, 78, 73, 71, 88, 57, 88, 77, 80, 87, 18, 76, 69, 90, 77, 82, 75, 12, 12, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 13, 83, 70, 78, 16, 225, 74, 77, 73, 80, 72, 21, 16, 225, 90, 69, 80, 89, 73, 21, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 31, 225, 97, 203, 2, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 173])\n",
      "torch.Size([2, 173])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "%%\n",
      "[[0, 36, 51, 90, 73, 86, 86, 77, 72, 73, 225, 84, 89, 70, 80, 77, 71, 225, 49, 69, 84, 51, 70, 78, 73, 71, 88, 49, 69, 84, 225, 76, 69, 90, 77, 82, 75, 12, 225, 55, 88, 86, 77, 82, 75, 225, 74, 77, 73, 80, 72, 21, 16, 225, 51, 70, 78, 73, 71, 88, 225, 90, 69, 80, 89, 73, 21, 13, 225, 95, 225, 77, 74, 12, 83, 70, 78, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 31, 225, 83, 70, 78, 225, 33, 225, 49, 69, 84, 51, 70, 78, 73, 71, 88, 57, 88, 77, 80, 87, 18, 76, 69, 90, 77, 82, 75, 12, 12, 39, 83, 80, 80, 73, 71, 88, 77, 83, 82, 13, 83, 70, 78, 16, 225, 74, 77, 73, 80, 72, 21, 16, 225, 90, 69, 80, 89, 73, 21, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 87, 93, 82, 71, 76, 86, 83, 82, 77, 94, 73, 72, 225, 70, 83, 83, 80, 73, 69, 82, 225, 69, 72, 72, 54, 73, 85, 89, 73, 87, 88, 52, 69, 86, 69, 81, 12, 55, 88, 86, 77, 82, 75, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 51, 70, 78, 73, 71, 88, 225, 261, 225, 77, 74, 225, 12, 84, 69, 86, 69, 81, 50, 69, 81, 73, 225, 33, 33, 225, 82, 89, 80, 80, 225, 96, 96, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 18, 88, 86, 77, 81, 12, 13, 18, 77, 87, 41, 81, 84, 88, 93, 12, 13, 225, 96, 96, 225, 90, 69, 80, 89, 73, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 74, 69, 80, 87, 73, 31, 225, 97, 225, 39, 80, 69, 87, 87, 32, 35, 34, 225, 71, 80, 69, 94, 94, 225, 33, 225, 90, 69, 80, 89, 73, 18, 75, 73, 88, 39, 80, 69, 87, 87, 12, 13, 31, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 225, 84, 69, 86, 69, 81, 73, 88, 73, 86, 225, 33, 225, 82, 73, 91, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 12, 88, 76, 77, 87, 18, 71, 83, 86, 86, 73, 80, 69, 88, 77, 83, 82, 45, 72, 16, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 71, 80, 69, 94, 94, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 69, 72, 72, 54, 73, 85, 89, 73, 87, 88, 52, 69, 86, 69, 81, 12, 84, 69, 86, 69, 81, 73, 88, 73, 86, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 329])\n",
      "torch.Size([2, 329])\n",
      "**\n",
      "335\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 87, 93, 82, 71, 76, 86, 83, 82, 77, 94, 73, 72, 225, 70, 83, 83, 80, 73, 69, 82, 225, 69, 72, 72, 54, 73, 85, 89, 73, 87, 88, 52, 69, 86, 69, 81, 12, 55, 88, 86, 77, 82, 75, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 51, 70, 78, 73, 71, 88, 225, 90, 69, 80, 89, 73, 13, 225, 95, 225, 77, 74, 225, 12, 84, 69, 86, 69, 81, 50, 69, 81, 73, 225, 33, 33, 225, 82, 89, 80, 80, 225, 96, 96, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 18, 88, 86, 77, 81, 12, 13, 18, 77, 87, 41, 81, 84, 88, 93, 12, 13, 225, 96, 96, 225, 90, 69, 80, 89, 73, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 225, 39, 80, 69, 87, 87, 32, 35, 34, 225, 71, 80, 69, 94, 94, 225, 33, 225, 90, 69, 80, 89, 73, 18, 75, 73, 88, 39, 80, 69, 87, 87, 12, 13, 31, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 225, 84, 69, 86, 69, 81, 73, 88, 73, 86, 225, 33, 225, 82, 73, 91, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 12, 88, 76, 77, 87, 18, 71, 83, 86, 86, 73, 80, 69, 88, 77, 83, 82, 45, 72, 16, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 71, 80, 69, 94, 94, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 69, 72, 72, 54, 73, 85, 89, 73, 87, 88, 52, 69, 86, 69, 81, 12, 84, 69, 86, 69, 81, 73, 88, 73, 86, 13, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 87, 93, 82, 71, 76, 86, 83, 82, 77, 94, 73, 72, 225, 70, 83, 83, 80, 73, 69, 82, 225, 69, 72, 72, 54, 73, 85, 89, 73, 87, 88, 52, 69, 86, 69, 81, 12, 55, 88, 86, 77, 82, 75, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 51, 70, 78, 73, 71, 88, 225, 90, 69, 80, 89, 73, 13, 225, 95, 225, 77, 74, 225, 12, 84, 69, 86, 69, 81, 50, 69, 81, 73, 225, 33, 33, 225, 82, 89, 80, 80, 225, 96, 96, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 18, 88, 86, 77, 81, 12, 13, 18, 77, 87, 41, 81, 84, 88, 93, 12, 13, 225, 96, 96, 225, 90, 69, 80, 89, 73, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 74, 69, 80, 87, 73, 31, 225, 97, 225, 39, 80, 69, 87, 87, 32, 35, 34, 225, 71, 80, 69, 94, 94, 225, 33, 225, 90, 69, 80, 89, 73, 18, 75, 73, 88, 39, 80, 69, 87, 87, 12, 225, 261, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 225, 84, 69, 86, 69, 81, 73, 88, 73, 86, 225, 33, 225, 82, 73, 91, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 12, 88, 76, 77, 87, 18, 71, 83, 86, 86, 73, 80, 69, 88, 77, 83, 82, 45, 72, 16, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 71, 80, 69, 94, 94, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 69, 72, 72, 54, 73, 85, 89, 73, 87, 88, 52, 69, 86, 69, 81, 12, 84, 69, 86, 69, 81, 73, 88, 73, 86, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 335])\n",
      "torch.Size([2, 335])\n",
      "**\n",
      "304\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 87, 93, 82, 71, 76, 86, 83, 82, 77, 94, 73, 72, 225, 70, 83, 83, 80, 73, 69, 82, 225, 69, 72, 72, 54, 73, 85, 89, 73, 87, 88, 52, 69, 86, 69, 81, 12, 55, 88, 86, 77, 82, 75, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 51, 70, 78, 73, 71, 88, 225, 90, 69, 80, 89, 73, 13, 225, 95, 225, 77, 74, 225, 12, 84, 69, 86, 69, 81, 50, 69, 81, 73, 225, 33, 33, 225, 82, 89, 80, 80, 225, 96, 96, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 18, 88, 86, 77, 81, 12, 13, 18, 77, 87, 41, 81, 84, 88, 93, 12, 13, 225, 96, 96, 225, 90, 69, 80, 89, 73, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 74, 69, 80, 87, 73, 31, 225, 97, 225, 39, 80, 69, 87, 87, 32, 35, 34, 225, 71, 80, 69, 94, 94, 225, 33, 225, 90, 69, 80, 89, 73, 18, 75, 73, 88, 39, 80, 69, 87, 87, 12, 13, 31, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 225, 84, 69, 86, 69, 81, 73, 88, 73, 86, 225, 33, 225, 82, 73, 91, 225, 52, 69, 86, 69, 81, 73, 88, 73, 86, 45, 82, 74, 83, 12, 88, 76, 77, 87, 18, 71, 83, 86, 86, 73, 80, 69, 88, 77, 83, 82, 45, 72, 16, 225, 84, 69, 86, 69, 81, 50, 69, 81, 73, 16, 225, 71, 80, 69, 94, 94, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 261, 225, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 225, 33, 225, 82, 73, 91, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 12, 13, 31, 225, 74, 83, 86, 225, 12, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 225, 86, 73, 87, 83, 89, 86, 71, 73, 225, 30, 225, 88, 76, 77, 87, 13, 225, 95, 225, 77, 74, 225, 12, 74, 77, 80, 88, 73, 86, 18, 69, 71, 71, 73, 84, 88, 12, 86, 73, 87, 83, 89, 86, 71, 73, 13, 13, 225, 95, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 18, 69, 72, 72, 12, 86, 73, 87, 83, 89, 86, 71, 73, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 304])\n",
      "torch.Size([2, 304])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 225, 74, 77, 80, 88, 73, 86, 12, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 225, 74, 77, 80, 88, 73, 86, 13, 225, 95, 225, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 225, 261, 225, 74, 83, 86, 225, 12, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 225, 86, 73, 87, 83, 89, 86, 71, 73, 225, 30, 225, 88, 76, 77, 87, 13, 225, 95, 225, 77, 74, 225, 12, 74, 77, 80, 88, 73, 86, 18, 69, 71, 71, 73, 84, 88, 12, 86, 73, 87, 83, 89, 86, 71, 73, 13, 13, 225, 95, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 18, 69, 72, 72, 12, 86, 73, 87, 83, 89, 86, 71, 73, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 225, 74, 77, 80, 88, 73, 86, 12, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 225, 74, 77, 80, 88, 73, 86, 13, 225, 95, 225, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 225, 33, 225, 82, 73, 91, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 12, 13, 31, 225, 74, 83, 86, 225, 12, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 225, 261, 225, 77, 74, 225, 12, 74, 77, 80, 88, 73, 86, 18, 69, 71, 71, 73, 84, 88, 12, 86, 73, 87, 83, 89, 86, 71, 73, 13, 13, 225, 95, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 18, 69, 72, 72, 12, 86, 73, 87, 83, 89, 86, 71, 73, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 250])\n",
      "torch.Size([2, 250])\n",
      "**\n",
      "249\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 225, 74, 77, 80, 88, 73, 86, 12, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 225, 74, 77, 80, 88, 73, 86, 13, 225, 95, 225, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 225, 33, 225, 82, 73, 91, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 48, 77, 87, 88, 12, 13, 31, 225, 74, 83, 86, 225, 12, 74, 77, 82, 69, 80, 225, 49, 83, 72, 89, 80, 73, 45, 82, 74, 83, 225, 86, 73, 87, 83, 89, 86, 71, 73, 225, 30, 225, 88, 76, 77, 87, 13, 225, 95, 225, 77, 74, 225, 12, 74, 77, 80, 88, 73, 86, 225, 261, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 18, 69, 72, 72, 12, 86, 73, 87, 83, 89, 86, 71, 73, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 81, 83, 72, 89, 80, 73, 45, 82, 74, 83, 42, 77, 80, 88, 73, 86, 73, 72, 31, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 261, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 87, 88, 73, 84, 225, 33, 225, 82, 73, 91, 225, 56, 73, 87, 88, 55, 88, 73, 84, 12, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 39, 89, 86, 86, 73, 82, 88, 39, 69, 87, 73, 50, 83, 12, 6, 20, 20, 21, 6, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 56, 73, 87, 88, 40, 69, 88, 69, 12, 6, 20, 20, 21, 6, 16, 225, 6, 93, 6, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 87, 88, 73, 84, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 249])\n",
      "torch.Size([2, 249])\n",
      "**\n",
      "137\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 71, 86, 73, 69, 88, 73, 12, 13, 225, 95, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 87, 88, 73, 84, 225, 33, 225, 82, 73, 91, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 261, 225, 87, 88, 73, 84, 18, 87, 73, 88, 39, 89, 86, 86, 73, 82, 88, 39, 69, 87, 73, 50, 83, 12, 6, 20, 20, 21, 6, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 56, 73, 87, 88, 40, 69, 88, 69, 12, 6, 20, 20, 21, 6, 16, 225, 6, 93, 6, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 87, 88, 73, 84, 31, 225, 97, 203, 2, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 71, 86, 73, 69, 88, 73, 12, 13, 225, 95, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 87, 88, 73, 84, 225, 33, 225, 82, 73, 91, 225, 56, 73, 87, 88, 55, 88, 73, 84, 12, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 39, 89, 86, 86, 73, 82, 88, 39, 69, 87, 73, 50, 83, 12, 6, 20, 20, 21, 6, 13, 225, 261, 225, 87, 88, 73, 84, 18, 87, 73, 88, 56, 73, 87, 88, 40, 69, 88, 69, 12, 6, 20, 20, 21, 6, 16, 225, 6, 93, 6, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 87, 88, 73, 84, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 137])\n",
      "torch.Size([2, 137])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 71, 86, 73, 69, 88, 73, 12, 13, 225, 95, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 87, 88, 73, 84, 225, 33, 225, 82, 73, 91, 225, 56, 73, 87, 88, 55, 88, 73, 84, 12, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 39, 89, 86, 86, 73, 82, 88, 39, 69, 87, 73, 50, 83, 12, 6, 20, 20, 21, 6, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 56, 73, 87, 88, 40, 69, 88, 69, 12, 6, 20, 20, 21, 6, 225, 261, 225, 86, 73, 88, 89, 86, 82, 225, 87, 88, 73, 84, 31, 225, 97, 203, 2, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 71, 86, 73, 69, 88, 73, 12, 13, 225, 95, 225, 56, 73, 87, 88, 55, 88, 73, 84, 225, 87, 88, 73, 84, 225, 33, 225, 82, 73, 91, 225, 56, 73, 87, 88, 55, 88, 73, 84, 12, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 39, 89, 86, 86, 73, 82, 88, 39, 69, 87, 73, 50, 83, 12, 6, 20, 20, 21, 6, 13, 31, 225, 87, 88, 73, 84, 18, 87, 73, 88, 56, 73, 87, 88, 40, 69, 88, 69, 12, 6, 20, 20, 21, 6, 16, 225, 6, 93, 6, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 225, 261, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 255])\n",
      "torch.Size([2, 255])\n",
      "**\n",
      "$$\n",
      "torch.Size([2, 520])\n",
      "torch.Size([2, 520])\n",
      "**\n",
      "270\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 55, 88, 86, 77, 82, 75, 225, 75, 73, 88, 39, 80, 69, 87, 87, 84, 69, 88, 76, 12, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 77, 82, 87, 88, 69, 82, 71, 73, 83, 74, 225, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 261, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 225, 75, 73, 88, 39, 80, 69, 87, 87, 52, 69, 88, 76, 12, 12, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 45, 80, 80, 73, 75, 69, 80, 37, 86, 75, 89, 81, 73, 82, 88, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 225, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 6, 225, 15, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 31, 225, 97, 203, 2], [0, 84, 86, 77, 90, 69, 88, 73, 225, 55, 88, 86, 77, 82, 75, 225, 75, 73, 88, 39, 80, 69, 87, 87, 84, 69, 88, 76, 12, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 77, 82, 87, 88, 69, 82, 71, 73, 83, 74, 225, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 95, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 225, 261, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 45, 80, 80, 73, 75, 69, 80, 37, 86, 75, 89, 81, 73, 82, 88, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 225, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 6, 225, 15, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 270])\n",
      "torch.Size([2, 270])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 55, 88, 86, 77, 82, 75, 225, 75, 73, 88, 39, 80, 69, 87, 87, 84, 69, 88, 76, 12, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 77, 82, 87, 88, 69, 82, 71, 73, 83, 74, 225, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 95, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 225, 75, 73, 88, 39, 80, 69, 87, 87, 52, 69, 88, 76, 12, 12, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 261, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 45, 80, 80, 73, 75, 69, 80, 37, 86, 75, 89, 81, 73, 82, 88, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 225, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 6, 225, 15, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 31, 225, 97, 203, 2], [0, 84, 86, 77, 90, 69, 88, 73, 225, 55, 88, 86, 77, 82, 75, 225, 75, 73, 88, 39, 80, 69, 87, 87, 84, 69, 88, 76, 12, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 77, 82, 87, 88, 69, 82, 71, 73, 83, 74, 225, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 95, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 225, 75, 73, 88, 39, 80, 69, 87, 87, 52, 69, 88, 76, 12, 12, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 45, 80, 80, 73, 75, 69, 80, 37, 86, 75, 89, 81, 73, 82, 88, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 225, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 6, 225, 261, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 271])\n",
      "torch.Size([2, 271])\n",
      "**\n",
      "272\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 55, 88, 86, 77, 82, 75, 225, 75, 73, 88, 39, 80, 69, 87, 87, 84, 69, 88, 76, 12, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 77, 74, 225, 12, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 77, 82, 87, 88, 69, 82, 71, 73, 83, 74, 225, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 95, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 33, 225, 75, 73, 88, 39, 80, 69, 87, 87, 52, 69, 88, 76, 12, 12, 57, 54, 48, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 45, 80, 80, 73, 75, 69, 80, 37, 86, 75, 89, 81, 73, 82, 88, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 225, 39, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 225, 6, 225, 15, 225, 71, 80, 69, 87, 87, 48, 83, 69, 72, 73, 86, 13, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 71, 80, 69, 87, 87, 52, 69, 88, 76, 225, 261, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 87, 73, 88, 37, 88, 88, 86, 77, 70, 89, 88, 73, 225, 261, 225, 77, 74, 12, 90, 69, 80, 89, 73, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 84, 89, 88, 12, 82, 69, 81, 73, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 86, 73, 81, 83, 90, 73, 12, 82, 69, 81, 73, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 272])\n",
      "torch.Size([2, 272])\n",
      "**\n",
      "155\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 87, 73, 88, 37, 88, 88, 86, 77, 70, 89, 88, 73, 12, 55, 88, 86, 77, 82, 75, 225, 82, 69, 81, 73, 16, 225, 37, 88, 88, 86, 77, 70, 89, 88, 73, 225, 90, 69, 80, 89, 73, 13, 225, 95, 225, 77, 74, 225, 261, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 84, 89, 88, 12, 82, 69, 81, 73, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 86, 73, 81, 83, 90, 73, 12, 82, 69, 81, 73, 13, 31, 225, 97, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 87, 73, 88, 37, 88, 88, 86, 77, 70, 89, 88, 73, 12, 55, 88, 86, 77, 82, 75, 225, 82, 69, 81, 73, 16, 225, 37, 88, 88, 86, 77, 70, 89, 88, 73, 225, 90, 69, 80, 89, 73, 13, 225, 95, 225, 77, 74, 12, 90, 69, 80, 89, 73, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 225, 261, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 86, 73, 81, 83, 90, 73, 12, 82, 69, 81, 73, 13, 31, 225, 97, 225, 97, 203, 2, 1]]\n",
      "$$\n",
      "torch.Size([2, 155])\n",
      "torch.Size([2, 155])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 87, 73, 88, 37, 88, 88, 86, 77, 70, 89, 88, 73, 12, 55, 88, 86, 77, 82, 75, 225, 82, 69, 81, 73, 16, 225, 37, 88, 88, 86, 77, 70, 89, 88, 73, 225, 90, 69, 80, 89, 73, 13, 225, 95, 225, 77, 74, 12, 90, 69, 80, 89, 73, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 84, 89, 88, 12, 82, 69, 81, 73, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 261, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 86, 73, 81, 83, 90, 73, 12, 82, 69, 81, 73, 13, 31, 225, 97, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 87, 73, 88, 37, 88, 88, 86, 77, 70, 89, 88, 73, 12, 55, 88, 86, 77, 82, 75, 225, 82, 69, 81, 73, 16, 225, 37, 88, 88, 86, 77, 70, 89, 88, 73, 225, 90, 69, 80, 89, 73, 13, 225, 95, 225, 77, 74, 12, 90, 69, 80, 89, 73, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 84, 89, 88, 12, 82, 69, 81, 73, 16, 225, 90, 69, 80, 89, 73, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 88, 76, 77, 87, 18, 69, 88, 88, 86, 77, 70, 89, 88, 73, 87, 18, 86, 73, 81, 83, 90, 73, 225, 261, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 263])\n",
      "torch.Size([2, 263])\n",
      "**\n",
      "299\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 70, 93, 88, 73, 63, 65, 225, 75, 89, 82, 94, 77, 84, 38, 93, 88, 73, 87, 12, 70, 93, 88, 73, 63, 65, 225, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 70, 83, 87, 225, 33, 225, 82, 73, 91, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 12, 12, 77, 82, 88, 13, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 18, 80, 73, 82, 75, 88, 76, 225, 14, 225, 21, 18, 25, 13, 13, 31, 225, 45, 82, 74, 80, 69, 88, 73, 86, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 261, 225, 72, 83, 87, 18, 91, 86, 77, 88, 73, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 13, 31, 225, 72, 83, 87, 18, 71, 80, 83, 87, 73, 12, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 83, 87, 18, 88, 83, 38, 93, 88, 73, 37, 86, 86, 69, 93, 12, 13, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 70, 93, 88, 73, 63, 65, 225, 75, 89, 82, 94, 77, 84, 38, 93, 88, 73, 87, 12, 70, 93, 88, 73, 63, 65, 225, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 70, 83, 87, 225, 33, 225, 82, 73, 91, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 12, 12, 77, 82, 88, 13, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 18, 80, 73, 82, 75, 88, 76, 225, 14, 225, 21, 18, 25, 13, 13, 31, 225, 45, 82, 74, 80, 69, 88, 73, 86, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 72, 83, 87, 225, 33, 225, 82, 73, 91, 225, 45, 82, 74, 80, 69, 88, 73, 86, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 12, 70, 83, 87, 13, 31, 225, 72, 83, 87, 18, 91, 86, 77, 88, 73, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 225, 261, 225, 72, 83, 87, 18, 71, 80, 83, 87, 73, 12, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 70, 83, 87, 18, 88, 83, 38, 93, 88, 73, 37, 86, 86, 69, 93, 12, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 299])\n",
      "torch.Size([2, 299])\n",
      "**\n",
      "292\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 70, 93, 88, 73, 63, 65, 225, 75, 89, 82, 94, 77, 84, 38, 93, 88, 73, 87, 12, 70, 93, 88, 73, 63, 65, 225, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 70, 83, 87, 225, 33, 225, 82, 73, 91, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 12, 12, 77, 82, 88, 13, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 18, 80, 73, 82, 75, 88, 76, 225, 14, 225, 21, 18, 25, 13, 13, 31, 225, 45, 82, 74, 80, 69, 88, 73, 86, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 72, 83, 87, 225, 33, 225, 82, 73, 91, 225, 45, 82, 74, 80, 69, 88, 73, 86, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 12, 70, 83, 87, 13, 31, 225, 72, 83, 87, 18, 91, 86, 77, 88, 73, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 13, 31, 225, 72, 83, 87, 225, 261, 225, 86, 73, 88, 89, 86, 82, 225, 70, 83, 87, 18, 88, 83, 38, 93, 88, 73, 37, 86, 86, 69, 93, 12, 13, 31, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 70, 93, 88, 73, 63, 65, 225, 75, 89, 82, 94, 77, 84, 38, 93, 88, 73, 87, 12, 70, 93, 88, 73, 63, 65, 225, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 70, 83, 87, 225, 33, 225, 82, 73, 91, 225, 38, 93, 88, 73, 37, 86, 86, 69, 93, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 12, 12, 77, 82, 88, 13, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 18, 80, 73, 82, 75, 88, 76, 225, 14, 225, 21, 18, 25, 13, 13, 31, 225, 45, 82, 74, 80, 69, 88, 73, 86, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 225, 72, 83, 87, 225, 33, 225, 82, 73, 91, 225, 45, 82, 74, 80, 69, 88, 73, 86, 51, 89, 88, 84, 89, 88, 55, 88, 86, 73, 69, 81, 12, 70, 83, 87, 13, 31, 225, 72, 83, 87, 18, 91, 86, 77, 88, 73, 12, 71, 83, 81, 84, 86, 73, 87, 87, 73, 72, 38, 93, 88, 73, 87, 13, 31, 225, 72, 83, 87, 18, 71, 80, 83, 87, 73, 12, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 292])\n",
      "torch.Size([2, 292])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 225, 261, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 33, 225, 75, 73, 88, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 12, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 33, 225, 90, 69, 86, 77, 69, 70, 80, 73, 87, 18, 88, 83, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 12, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 18, 71, 83, 82, 72, 77, 88, 77, 83, 82, 69, 80, 12, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 71, 83, 82, 72, 77, 88, 77, 83, 82, 69, 80, 12, 40, 93, 82, 69, 81, 77, 71, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 225, 95, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 261, 225, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 33, 225, 90, 69, 86, 77, 69, 70, 80, 73, 87, 18, 88, 83, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 12, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 18, 71, 83, 82, 72, 77, 88, 77, 83, 82, 69, 80, 12, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 222])\n",
      "torch.Size([2, 222])\n",
      "**\n",
      "258\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 71, 83, 82, 72, 77, 88, 77, 83, 82, 69, 80, 12, 40, 93, 82, 69, 81, 77, 71, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 225, 95, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 33, 225, 75, 73, 88, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 12, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 33, 225, 90, 69, 86, 77, 69, 70, 80, 73, 87, 225, 261, 225, 86, 73, 88, 89, 86, 82, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 18, 71, 83, 82, 72, 77, 88, 77, 83, 82, 69, 80, 12, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 71, 83, 82, 72, 77, 88, 77, 83, 82, 69, 80, 12, 40, 93, 82, 69, 81, 77, 71, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 225, 95, 225, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 225, 33, 225, 75, 73, 88, 42, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 12, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 33, 225, 90, 69, 86, 77, 69, 70, 80, 73, 87, 18, 88, 83, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 12, 69, 87, 87, 77, 75, 82, 81, 73, 82, 88, 13, 31, 225, 86, 73, 88, 89, 86, 82, 225, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 18, 71, 83, 82, 72, 77, 88, 77, 83, 82, 69, 80, 12, 74, 69, 71, 88, 83, 86, 43, 86, 69, 84, 76, 37, 87, 87, 77, 75, 82, 81, 73, 82, 88, 225, 261, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 258])\n",
      "torch.Size([2, 258])\n",
      "**\n",
      "285\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 225, 261, 225, 95, 225, 88, 86, 93, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 81, 69, 82, 69, 75, 73, 86, 18, 75, 73, 88, 45, 82, 87, 88, 69, 82, 71, 73, 12, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 18, 71, 80, 69, 87, 87, 16, 225, 76, 77, 82, 88, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 39, 83, 81, 84, 83, 82, 73, 82, 88, 48, 83, 83, 79, 89, 84, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 51, 84, 73, 86, 69, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 52, 69, 87, 87, 91, 83, 86, 72, 225, 70, 69, 87, 73, 72, 225, 71, 77, 84, 76, 73, 86, 225, 74, 69, 71, 88, 83, 86, 93, 225, 82, 83, 88, 225, 74, 83, 89, 82, 72, 30, 225, 6, 225, 15, 225, 76, 77, 82, 88, 16, 225, 73, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 225, 75, 73, 88, 52, 38, 41, 42, 69, 71, 88, 83, 86, 93, 12, 55, 88, 86, 77, 82, 75, 225, 76, 77, 82, 88, 13, 225, 95, 225, 88, 86, 93, 225, 225, 261, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 81, 69, 82, 69, 75, 73, 86, 18, 75, 73, 88, 45, 82, 87, 88, 69, 82, 71, 73, 12, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 18, 71, 80, 69, 87, 87, 16, 225, 76, 77, 82, 88, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 39, 83, 81, 84, 83, 82, 73, 82, 88, 48, 83, 83, 79, 89, 84, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 51, 84, 73, 86, 69, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 52, 69, 87, 87, 91, 83, 86, 72, 225, 70, 69, 87, 73, 72, 225, 71, 77, 84, 76, 73, 86, 225, 74, 69, 71, 88, 83, 86, 93, 225, 82, 83, 88, 225, 74, 83, 89, 82, 72, 30, 225, 6, 225, 15, 225, 76, 77, 82, 88, 16, 225, 73, 13, 31, 225, 97, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 285])\n",
      "torch.Size([2, 285])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 225, 75, 73, 88, 52, 38, 41, 42, 69, 71, 88, 83, 86, 93, 12, 55, 88, 86, 77, 82, 75, 225, 76, 77, 82, 88, 13, 225, 95, 225, 88, 86, 93, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 81, 69, 82, 69, 75, 73, 86, 18, 75, 73, 88, 45, 82, 87, 88, 69, 82, 71, 73, 12, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 225, 261, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 39, 83, 81, 84, 83, 82, 73, 82, 88, 48, 83, 83, 79, 89, 84, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 51, 84, 73, 86, 69, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 52, 69, 87, 87, 91, 83, 86, 72, 225, 70, 69, 87, 73, 72, 225, 71, 77, 84, 76, 73, 86, 225, 74, 69, 71, 88, 83, 86, 93, 225, 82, 83, 88, 225, 74, 83, 89, 82, 72, 30, 225, 6, 225, 15, 225, 76, 77, 82, 88, 16, 225, 73, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 225, 75, 73, 88, 52, 38, 41, 42, 69, 71, 88, 83, 86, 93, 12, 55, 88, 86, 77, 82, 75, 225, 76, 77, 82, 88, 13, 225, 95, 225, 88, 86, 93, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 81, 69, 82, 69, 75, 73, 86, 18, 75, 73, 88, 45, 82, 87, 88, 69, 82, 71, 73, 12, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 18, 71, 80, 69, 87, 87, 16, 225, 76, 77, 82, 88, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 39, 83, 81, 84, 83, 82, 73, 82, 88, 48, 83, 83, 79, 89, 84, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 261, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 51, 84, 73, 86, 69, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 52, 69, 87, 87, 91, 83, 86, 72, 225, 70, 69, 87, 73, 72, 225, 71, 77, 84, 76, 73, 86, 225, 74, 69, 71, 88, 83, 86, 93, 225, 82, 83, 88, 225, 74, 83, 89, 82, 72, 30, 225, 6, 225, 15, 225, 76, 77, 82, 88, 16, 225, 73, 13, 31, 225, 97, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 281])\n",
      "torch.Size([2, 281])\n",
      "**\n",
      "274\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 225, 75, 73, 88, 52, 38, 41, 42, 69, 71, 88, 83, 86, 93, 12, 55, 88, 86, 77, 82, 75, 225, 76, 77, 82, 88, 13, 225, 95, 225, 88, 86, 93, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 88, 76, 77, 87, 18, 81, 69, 82, 69, 75, 73, 86, 18, 75, 73, 88, 45, 82, 87, 88, 69, 82, 71, 73, 12, 52, 69, 87, 87, 91, 83, 86, 72, 38, 69, 87, 73, 72, 39, 77, 84, 76, 73, 86, 42, 69, 71, 88, 83, 86, 93, 18, 71, 80, 69, 87, 87, 16, 225, 76, 77, 82, 88, 13, 31, 225, 97, 225, 71, 69, 88, 71, 76, 225, 12, 39, 83, 81, 84, 83, 82, 73, 82, 88, 48, 83, 83, 79, 89, 84, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 73, 13, 225, 95, 225, 88, 76, 86, 83, 91, 225, 82, 73, 91, 225, 57, 82, 87, 89, 84, 84, 83, 86, 88, 73, 72, 51, 84, 73, 86, 69, 88, 77, 83, 82, 41, 92, 71, 73, 84, 88, 77, 83, 82, 12, 6, 52, 69, 87, 87, 91, 83, 86, 72, 225, 70, 69, 87, 73, 72, 225, 71, 77, 84, 76, 73, 86, 225, 74, 69, 71, 88, 83, 86, 93, 225, 82, 83, 88, 225, 74, 83, 89, 82, 72, 30, 225, 6, 225, 261, 225, 97, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 32, 56, 225, 73, 92, 88, 73, 82, 72, 87, 225, 49, 69, 82, 69, 75, 73, 69, 70, 80, 73, 34, 225, 56, 225, 74, 77, 82, 72, 12, 39, 80, 69, 87, 87, 32, 35, 225, 73, 92, 88, 73, 82, 72, 87, 225, 56, 34, 225, 77, 88, 73, 81, 56, 93, 84, 73, 16, 225, 55, 88, 86, 77, 82, 75, 225, 77, 72, 13, 225, 95, 225, 74, 83, 86, 225, 12, 43, 86, 83, 89, 84, 51, 74, 32, 56, 34, 225, 75, 86, 83, 89, 84, 225, 30, 225, 225, 261, 225, 56, 225, 81, 73, 81, 70, 73, 86, 225, 33, 225, 75, 86, 83, 89, 84, 18, 74, 77, 82, 72, 12, 77, 72, 13, 31, 225, 77, 74, 225, 12, 81, 73, 81, 70, 73, 86, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 81, 73, 81, 70, 73, 86, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 82, 89, 80, 80, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 274])\n",
      "torch.Size([2, 274])\n",
      "**\n",
      "213\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 32, 56, 225, 73, 92, 88, 73, 82, 72, 87, 225, 49, 69, 82, 69, 75, 73, 69, 70, 80, 73, 34, 225, 56, 225, 74, 77, 82, 72, 12, 39, 80, 69, 87, 87, 32, 35, 225, 73, 92, 88, 73, 82, 72, 87, 225, 56, 34, 225, 77, 88, 73, 81, 56, 93, 84, 73, 16, 225, 55, 88, 86, 77, 82, 75, 225, 77, 72, 13, 225, 95, 225, 74, 83, 86, 225, 12, 43, 86, 83, 89, 84, 51, 74, 32, 56, 34, 225, 75, 86, 83, 89, 84, 225, 30, 225, 43, 86, 83, 89, 84, 87, 18, 74, 77, 82, 72, 12, 77, 88, 73, 81, 56, 93, 84, 73, 13, 13, 225, 95, 225, 56, 225, 81, 73, 81, 70, 73, 86, 225, 33, 225, 225, 261, 225, 77, 74, 225, 12, 81, 73, 81, 70, 73, 86, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 81, 73, 81, 70, 73, 86, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 82, 89, 80, 80, 31, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 32, 56, 225, 73, 92, 88, 73, 82, 72, 87, 225, 49, 69, 82, 69, 75, 73, 69, 70, 80, 73, 34, 225, 56, 225, 74, 77, 82, 72, 12, 39, 80, 69, 87, 87, 32, 35, 225, 73, 92, 88, 73, 82, 72, 87, 225, 56, 34, 225, 77, 88, 73, 81, 56, 93, 84, 73, 16, 225, 55, 88, 86, 77, 82, 75, 225, 77, 72, 13, 225, 95, 225, 74, 83, 86, 225, 12, 43, 86, 83, 89, 84, 51, 74, 32, 56, 34, 225, 75, 86, 83, 89, 84, 225, 30, 225, 43, 86, 83, 89, 84, 87, 18, 74, 77, 82, 72, 12, 77, 88, 73, 81, 56, 93, 84, 73, 13, 13, 225, 95, 225, 56, 225, 81, 73, 81, 70, 73, 86, 225, 33, 225, 75, 86, 83, 89, 84, 18, 74, 77, 82, 72, 12, 77, 72, 13, 31, 225, 77, 74, 225, 261, 225, 86, 73, 88, 89, 86, 82, 225, 81, 73, 81, 70, 73, 86, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 82, 89, 80, 80, 31, 225, 97, 203, 2, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 213])\n",
      "torch.Size([2, 213])\n",
      "**\n",
      "336\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 32, 56, 225, 73, 92, 88, 73, 82, 72, 87, 225, 49, 69, 82, 69, 75, 73, 69, 70, 80, 73, 34, 225, 56, 225, 74, 77, 82, 72, 12, 39, 80, 69, 87, 87, 32, 35, 225, 73, 92, 88, 73, 82, 72, 87, 225, 56, 34, 225, 77, 88, 73, 81, 56, 93, 84, 73, 16, 225, 55, 88, 86, 77, 82, 75, 225, 77, 72, 13, 225, 95, 225, 74, 83, 86, 225, 12, 43, 86, 83, 89, 84, 51, 74, 32, 56, 34, 225, 75, 86, 83, 89, 84, 225, 30, 225, 43, 86, 83, 89, 84, 87, 18, 74, 77, 82, 72, 12, 77, 88, 73, 81, 56, 93, 84, 73, 13, 13, 225, 95, 225, 56, 225, 81, 73, 81, 70, 73, 86, 225, 33, 225, 75, 86, 83, 89, 84, 18, 74, 77, 82, 72, 12, 77, 72, 13, 31, 225, 77, 74, 225, 12, 81, 73, 81, 70, 73, 86, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 82, 89, 80, 80, 31, 225, 97, 203, 2, 1, 1], [0, 84, 89, 70, 80, 77, 71, 225, 87, 88, 69, 88, 77, 71, 225, 32, 56, 225, 73, 92, 88, 73, 82, 72, 87, 225, 49, 69, 82, 69, 75, 73, 69, 70, 80, 73, 34, 225, 56, 225, 74, 77, 82, 72, 12, 39, 80, 69, 87, 87, 32, 35, 225, 73, 92, 88, 73, 82, 72, 87, 225, 56, 34, 225, 77, 88, 73, 81, 56, 93, 84, 73, 16, 225, 55, 88, 86, 77, 82, 75, 225, 77, 72, 13, 225, 95, 225, 74, 83, 86, 225, 12, 43, 86, 83, 89, 84, 51, 74, 32, 56, 34, 225, 75, 86, 83, 89, 84, 225, 30, 225, 43, 86, 83, 89, 84, 87, 18, 74, 77, 82, 72, 12, 77, 88, 73, 81, 56, 93, 84, 73, 13, 13, 225, 95, 225, 56, 225, 81, 73, 81, 70, 73, 86, 225, 33, 225, 75, 86, 83, 89, 84, 18, 74, 77, 82, 72, 12, 77, 72, 13, 31, 225, 77, 74, 225, 12, 81, 73, 81, 70, 73, 86, 5, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 86, 73, 88, 89, 86, 82, 225, 81, 73, 81, 70, 73, 86, 31, 225, 97, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 261, 225, 97, 203, 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$\n",
      "torch.Size([2, 336])\n",
      "torch.Size([2, 336])\n",
      "**\n",
      "371\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 70, 83, 83, 80, 73, 69, 82, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 225, 261, 225, 38, 83, 83, 80, 73, 69, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 75, 73, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 13, 31, 225, 77, 74, 225, 12, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 70, 72, 69, 18, 76, 69, 87, 38, 73, 69, 82, 87, 12, 13, 225, 96, 96, 225, 70, 72, 69, 18, 77, 87, 41, 92, 88, 73, 82, 87, 77, 83, 82, 12, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 96, 96, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 70, 72, 69, 18, 75, 73, 88, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 87, 12, 13, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 70, 83, 83, 80, 73, 69, 82, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 225, 70, 72, 69, 13, 225, 95, 225, 38, 83, 83, 80, 73, 69, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 75, 73, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 225, 261, 225, 77, 74, 225, 12, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 70, 72, 69, 18, 76, 69, 87, 38, 73, 69, 82, 87, 12, 13, 225, 96, 96, 225, 70, 72, 69, 18, 77, 87, 41, 92, 88, 73, 82, 87, 77, 83, 82, 12, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 96, 96, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 70, 72, 69, 18, 75, 73, 88, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 87, 12, 13, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 371])\n",
      "torch.Size([2, 371])\n",
      "**\n",
      "372\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 70, 83, 83, 80, 73, 69, 82, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 225, 70, 72, 69, 13, 225, 95, 225, 38, 83, 83, 80, 73, 69, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 75, 73, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 13, 31, 225, 77, 74, 225, 12, 76, 69, 87, 38, 73, 69, 82, 87, 225, 261, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 70, 72, 69, 18, 76, 69, 87, 38, 73, 69, 82, 87, 12, 13, 225, 96, 96, 225, 70, 72, 69, 18, 77, 87, 41, 92, 88, 73, 82, 87, 77, 83, 82, 12, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 96, 96, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 70, 72, 69, 18, 75, 73, 88, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 87, 12, 13, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 70, 83, 83, 80, 73, 69, 82, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 225, 70, 72, 69, 13, 225, 95, 225, 38, 83, 83, 80, 73, 69, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 75, 73, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 13, 31, 225, 77, 74, 225, 12, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 70, 72, 69, 18, 76, 69, 87, 38, 73, 69, 82, 87, 12, 13, 225, 96, 96, 225, 70, 72, 69, 18, 77, 87, 41, 92, 88, 73, 82, 87, 77, 83, 82, 225, 261, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 96, 96, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 70, 72, 69, 18, 75, 73, 88, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 87, 12, 13, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 31, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 372])\n",
      "torch.Size([2, 372])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n",
      "%%\n",
      "[[0, 84, 86, 77, 90, 69, 88, 73, 225, 70, 83, 83, 80, 73, 69, 82, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 225, 70, 72, 69, 13, 225, 95, 225, 38, 83, 83, 80, 73, 69, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 75, 73, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 13, 31, 225, 77, 74, 225, 12, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 70, 72, 69, 18, 76, 69, 87, 38, 73, 69, 82, 87, 12, 13, 225, 96, 96, 225, 70, 72, 69, 18, 77, 87, 41, 92, 88, 73, 82, 87, 77, 83, 82, 12, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 96, 96, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 225, 261, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 31, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 84, 86, 77, 90, 69, 88, 73, 225, 70, 83, 83, 80, 73, 69, 82, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 225, 70, 72, 69, 13, 225, 95, 225, 38, 83, 83, 80, 73, 69, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 75, 73, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 13, 31, 225, 77, 74, 225, 12, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 70, 72, 69, 18, 76, 69, 87, 38, 73, 69, 82, 87, 12, 13, 225, 96, 96, 225, 70, 72, 69, 18, 77, 87, 41, 92, 88, 73, 82, 87, 77, 83, 82, 12, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 33, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 96, 96, 225, 77, 87, 39, 40, 45, 41, 82, 69, 70, 80, 73, 72, 12, 70, 72, 69, 18, 75, 73, 88, 59, 73, 70, 55, 84, 76, 73, 86, 73, 38, 73, 69, 82, 40, 73, 84, 80, 83, 93, 81, 73, 82, 88, 37, 86, 71, 76, 77, 90, 73, 87, 12, 13, 13, 31, 225, 71, 72, 77, 55, 88, 69, 88, 89, 87, 49, 69, 84, 18, 84, 89, 88, 12, 70, 72, 69, 18, 75, 73, 88, 45, 72, 12, 13, 16, 225, 76, 69, 87, 38, 73, 69, 82, 87, 13, 31, 225, 97, 225, 86, 73, 88, 89, 86, 82, 225, 76, 69, 87, 38, 73, 69, 82, 87, 225, 261, 225, 97, 203, 2]]\n",
      "$$\n",
      "torch.Size([2, 374])\n",
      "torch.Size([2, 374])\n",
      "**\n",
      "124\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 91, 86, 77, 88, 73, 12, 42, 80, 83, 69, 88, 225, 74, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 261, 225, 77, 74, 225, 12, 74, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 91, 86, 77, 88, 73, 12, 6, 82, 89, 80, 80, 17, 74, 80, 83, 69, 88, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 91, 86, 77, 88, 73, 12, 74, 18, 74, 80, 83, 69, 88, 58, 69, 80, 89, 73, 12, 13, 13, 31, 225, 97, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 91, 86, 77, 88, 73, 12, 42, 80, 83, 69, 88, 225, 74, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 77, 74, 225, 12, 74, 225, 225, 261, 225, 91, 86, 77, 88, 73, 12, 6, 82, 89, 80, 80, 17, 74, 80, 83, 69, 88, 6, 13, 31, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 91, 86, 77, 88, 73, 12, 74, 18, 74, 80, 83, 69, 88, 58, 69, 80, 89, 73, 12, 13, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 124])\n",
      "torch.Size([2, 124])\n",
      "**\n",
      "124\n",
      "%%\n",
      "[[0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 91, 86, 77, 88, 73, 12, 42, 80, 83, 69, 88, 225, 74, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 77, 74, 225, 12, 74, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 91, 86, 77, 88, 73, 12, 6, 82, 89, 80, 80, 17, 74, 80, 83, 69, 88, 6, 225, 261, 225, 97, 225, 73, 80, 87, 73, 225, 95, 225, 91, 86, 77, 88, 73, 12, 74, 18, 74, 80, 83, 69, 88, 58, 69, 80, 89, 73, 12, 13, 13, 31, 225, 97, 225, 97, 203, 2], [0, 84, 89, 70, 80, 77, 71, 225, 90, 83, 77, 72, 225, 91, 86, 77, 88, 73, 12, 42, 80, 83, 69, 88, 225, 74, 13, 225, 88, 76, 86, 83, 91, 87, 225, 45, 51, 41, 92, 71, 73, 84, 88, 77, 83, 82, 225, 95, 225, 77, 74, 225, 12, 74, 225, 33, 33, 225, 82, 89, 80, 80, 13, 225, 95, 225, 91, 86, 77, 88, 73, 12, 6, 82, 89, 80, 80, 17, 74, 80, 83, 69, 88, 6, 13, 31, 225, 97, 225, 225, 261, 225, 91, 86, 77, 88, 73, 12, 74, 18, 74, 80, 83, 69, 88, 58, 69, 80, 89, 73, 12, 13, 13, 31, 225, 97, 225, 97, 203, 2, 1, 1, 1, 1]]\n",
      "$$\n",
      "torch.Size([2, 124])\n",
      "torch.Size([2, 124])\n",
      "**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   1%|          | 53/8453 [00:04<11:23, 12.29it/s]\n",
      "Epoch:   0%|          | 0/1 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$\n",
      "torch.Size([2, 1065])\n",
      "torch.Size([2, 1065])\n",
      "**\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1065) must match the existing size (1024) at non-singleton dimension 1.  Target sizes: [2, 1065].  Tensor sizes: [1, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m global_step, tr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m global_step = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, average loss = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, global_step, tr_loss)\n",
      "Cell \u001b[0;32mIn[55], line 141\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, train_dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 141\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmlm \u001b[38;5;28;01melse\u001b[39;00m model(inputs, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m    142\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# model outputs are always tuple in transformers (see doc)\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv_python3_11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv_python3_11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv_python3_11/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:1084\u001b[0m, in \u001b[0;36mRobertaForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    Used to hide legacy arguments that have been deprecated.\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1084\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1098\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv_python3_11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv_python3_11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv_python3_11/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:801\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    800\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 801\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1065) must match the existing size (1024) at non-singleton dimension 1.  Target sizes: [2, 1065].  Tensor sizes: [1, 1024]"
     ]
    }
   ],
   "source": [
    "global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
    "logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84513183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "#         # Create output directory if needed\n",
    "#         if args.local_rank in [-1, 0]:\n",
    "#             os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "#         logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "#         # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "#         # They can then be reloaded using `from_pretrained()`\n",
    "#         model_to_save = (\n",
    "#             model.module if hasattr(model, \"module\") else model\n",
    "#         )  # Take care of distributed/parallel training\n",
    "#         model_to_save.save_pretrained(args.output_dir)\n",
    "#         tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "#         # Good practice: save your training arguments together with the trained model\n",
    "#         torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "\n",
    "#         # Load a trained model and vocabulary that you have fine-tuned\n",
    "#         model = model_class.from_pretrained(args.output_dir)\n",
    "#         tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n",
    "#         model.to(args.device)\n",
    "\n",
    "#     # Evaluation\n",
    "# results = {}\n",
    "# if args.do_eval and args.local_rank in [-1, 0]:\n",
    "#         checkpoints = [args.output_dir]\n",
    "#         if args.eval_all_checkpoints:\n",
    "#             checkpoints = list(\n",
    "#                 os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
    "#             )\n",
    "#             logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "#         logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "#         for checkpoint in checkpoints:\n",
    "#             global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "#             prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
    "\n",
    "#             model = model_class.from_pretrained(checkpoint)\n",
    "#             model.to(args.device)\n",
    "#             result = evaluate(args, model, tokenizer, prefix=prefix)\n",
    "#             if result is None:\n",
    "#                 print(\"Stopping condition reached, no improvement in evaluation set\")\n",
    "#                 sys.exit(0)\n",
    "#             result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "#             results.update(result)\n",
    "\n",
    "# return results"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding=utf-8",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "myenv_python3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
